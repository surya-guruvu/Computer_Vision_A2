{"cells":[{"cell_type":"markdown","metadata":{"id":"8KeRr-mWQiBX"},"source":["**Imports**"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1078,"status":"ok","timestamp":1678888008976,"user":{"displayName":"surya sai","userId":"02542796707014091485"},"user_tz":-330},"id":"-t-nhVW4Q1P7"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.datasets import mnist\n","import numpy as np\n","import math\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.preprocessing import LabelBinarizer\n","import cv2\n","import numpy as np\n","from tensorflow.keras.datasets import cifar10\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","metadata":{"id":"LayP7SZZQ6xg"},"source":["**Optimizers**"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678888009601,"user":{"displayName":"surya sai","userId":"02542796707014091485"},"user_tz":-330},"id":"x9eiDqiAQ9-m"},"outputs":[],"source":["def adam_opt(model,l_rate):\n","  optimizer = tf.keras.optimizers.Adam(\n","      learning_rate=l_rate,\n","      beta_1=0.9,\n","      beta_2=0.999,\n","      epsilon=1e-07)\n","  model.compile(\n","      optimizer=optimizer, \n","      loss=tf.keras.losses.sparse_categorical_crossentropy, \n","      metrics=['accuracy']\n","  )\n","  return model\n","\n","def rms_prop(model,l_rate):\n","  optimizer = tf.keras.optimizers.experimental.RMSprop(\n","      learning_rate=l_rate,\n","      rho=0.9,\n","      epsilon=1e-07)\n","  model.compile(\n","      optimizer=optimizer, \n","      loss=tf.keras.losses.sparse_categorical_crossentropy, \n","      metrics=['accuracy']\n","  )\n","  return model\n","  \n","def momentum_gd(model,l_rate):\n","  optimizer = tf.keras.optimizers.experimental.SGD(\n","      learning_rate=l_rate,\n","      momentum=0.9,\n","      nesterov=False) #################\n","  model.compile(\n","      optimizer=optimizer, \n","      loss=tf.keras.losses.sparse_categorical_crossentropy, \n","      metrics=['accuracy']\n","  )\n","  return model\n","\n","def vanilla_gd(model,l_rate):\n","  optimizer = tf.keras.optimizers.experimental.SGD(\n","      learning_rate=l_rate,\n","      momentum=0.0)\n","  model.compile(\n","      optimizer=optimizer, \n","      loss=tf.keras.losses.sparse_categorical_crossentropy, \n","      metrics=['accuracy']\n","  )\n","  return model\n"]},{"cell_type":"markdown","metadata":{"id":"nYeiBryUZ9xR"},"source":["**Data Preprocessing**"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2622,"status":"ok","timestamp":1678888012220,"user":{"displayName":"surya sai","userId":"02542796707014091485"},"user_tz":-330},"id":"QonwzUK3UQus","outputId":"470c427f-0110-49fc-bf5e-60043a1e5592"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape:  (4166, 32, 32, 3)\n","Y_train shape:  (4166, 1)\n","X_test shape:  (10000, 32, 32, 3)\n","Y_test shape:  (10000, 1)\n"]}],"source":["# Load the CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Select 500 images per class from the training set\n","num_classes = 10\n","num_samples_per_class = 500\n","x_train_tiny = np.zeros((num_classes*num_samples_per_class, 32, 32, 3))\n","y_train_tiny = np.zeros((num_classes*num_samples_per_class, 1))\n","for class_idx in range(num_classes):\n","    class_indices = np.where(y_train == class_idx)[0]\n","    random_indices = np.random.choice(class_indices, num_samples_per_class, replace=False)\n","    x_train_tiny[class_idx*num_samples_per_class:(class_idx+1)*num_samples_per_class,:,:,:] = x_train[random_indices,:,:,:]\n","    y_train_tiny[class_idx*num_samples_per_class:(class_idx+1)*num_samples_per_class,:] = y_train[random_indices,:]\n","\n","# Use the same 10,000 images for testing as per the CIFAR-10 dataset\n","X_test = x_test\n","Y_test = y_test\n","\n","X_train = x_train_tiny\n","Y_train = y_train_tiny\n","# print(np.where(y_train == 0))\n","\n","#Normalizing data\n","mean = np.mean(X_train, axis=(0, 1, 2))\n","std = np.std(X_train, axis=(0, 1, 2))\n","X_train = (X_train - mean) / std\n","X_test = (X_test - mean) / std  ####################\n","\n","n_rows = X_train.shape[0]\n","perm = np.random.permutation(n_rows)\n","X_train = X_train[perm]\n","Y_train = Y_train[perm]\n","\n","\n","\n","X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.16666, random_state=42)\n","\n","\n","\n","\n","print(\"X_train shape: \",X_train.shape)\n","print(\"Y_train shape: \",Y_train.shape)\n","print(\"X_test shape: \",X_test.shape)\n","print(\"Y_test shape: \",Y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"U4SLsO6-aCbt"},"source":["**Implementing ResNet-18 architecture**"]},{"cell_type":"markdown","metadata":{"id":"Ins-KDxzKRTN"},"source":["When we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. \n","\n","In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together.\n","\n","The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.\n","\n","Apart from the vanishing gradients, there is another reason that we commonly use them. For a plethora of tasks there is some information that was captured in the initial layers and we would like to allow the later layers to also learn from them.\n","\n","In ResNet-18, downsample is used in the residual blocks where the stride is greater than 1. When the stride is greater than 1, the convolutional layer reduces the spatial dimensions of the input feature map. However, the shortcut connection (i.e., the skip connection) requires the output of the convolutional layer to have the same dimensions as the input feature map. To achieve this, downsample is used to perform spatial downsampling on the input feature map before adding it to the output of the convolutional layer.\n","\n","**For Implementing this architecture we use functional API instead of sequential API** because of its flexiblity.\n","\n","ResNet18 is a neural network architecture that consists of 18 layers, which are:\n","\n","1. Convolutional layer with 64 filters and kernel size of 7x7\n","Batch normalization layer\n","2. Rectified Linear Unit (ReLU) activation function\n","3. Max pooling layer with pool size of 3x3 and stride of 2\n","4. 2 ResNet blocks, each containing 2 convolutional layers with 64 filters, kernel size of 3x3 and stride of 1, followed by batch normalization and ReLU activation function\n","5. 2 ResNet blocks, each containing 2 convolutional layers with 128 filters, kernel size of 3x3 and stride of 2 (except for the first layer in each block which has a stride of 2), followed by batch normalization and ReLU activation function\n","6. 2 ResNet blocks, each containing 2 convolutional layers with 256 filters, kernel size of 3x3 and stride of 2 (except for the first layer in each block which has a stride of 2), followed by batch normalization and ReLU activation function\n","7. 2 ResNet blocks, each containing 2 convolutional layers with 512 filters, kernel size of 3x3 and stride of 2 (except for the first layer in each block which has a stride of 2), followed by batch normalization and ReLU activation function\n","8. Global average pooling layer\n","9. Fully connected layer with 10 units and softmax activation function\n","\n","\n","Note that some of the layers in ResNet18 are repeated, which is why there are a total of 18 layers in the architecture."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1678894040301,"user":{"displayName":"surya sai","userId":"02542796707014091485"},"user_tz":-330},"id":"w1B0PPiqaQTE"},"outputs":[],"source":["def residual_block(x, filters, stride, downsample=None): #H(x) = F(x)+x\n","    residual = x \n","\n","\n","    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=stride, padding='same')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.Activation('relu')(x)\n","\n","    x = tf.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","\n","    if downsample is not None:\n","        residual = downsample(residual)\n","\n","    x = tf.keras.layers.Add()([x, residual]) #does element-wise addition\n","    x = tf.keras.layers.Activation('relu')(x)\n","\n","    return x\n","\n","def ResNet18(num_classes,input_shape = (32,32,3)):\n","    input_tensor = tf.keras.layers.Input(shape=input_shape)\n","\n","        # randomly flip the image horizontally\n","    x = tf.image.random_flip_left_right(input_tensor)\n","\n","    # randomly rotate the image by up to 15 degrees\n","    x = tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","\n","    # randomly adjust the brightness of the image\n","    x = tf.image.random_brightness(x, max_delta=0.2)\n","\n","    # randomly adjust the contrast of the image\n","    x = tf.image.random_contrast(x, lower=0.2, upper=1.8)\n","\n","    x = RandomZoom(0.2)(x)\n","\n","    x = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=2, padding='same')(x) #layer-1\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.Activation('relu')(x)\n","    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n","\n","    filters = 64 #layer 2-5\n","    x = residual_block(x, filters,stride=1)\n","    x = residual_block(x, filters,stride=1)\n","\n","    filters *= 2 #layer 6-9\n","    downsample = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=2, padding='same')\n","    x = residual_block(x, filters, stride=2,downsample=downsample)\n","    x = residual_block(x, filters,stride=1)\n","\n","    filters *= 2 #layer 10-13\n","    downsample = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=2, padding='same')\n","    x = residual_block(x, filters, stride=2, downsample=downsample)\n","    x = residual_block(x, filters,stride=1)\n","\n","    filters *= 2 #layer 14-17\n","    downsample = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=2, padding='same')\n","    x = residual_block(x, filters, stride=2, downsample=downsample)\n","    x = residual_block(x, filters,stride=1)\n","\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    output_tensor = tf.keras.layers.Dense(num_classes, activation='softmax')(x) #layer-18\n","\n","    model = tf.keras.models.Model(input_tensor, output_tensor)\n","\n","    return model\n","\n","\n","def ResNet18_d(num_classes,x1,x2,x3,x4,dr,input_shape = (32,32,3)):\n","    input_tensor = tf.keras.layers.Input(shape=input_shape)\n","\n","        # randomly flip the image horizontally\n","    x = tf.image.random_flip_left_right(input_tensor)\n","\n","    # randomly rotate the image by up to 15 degrees\n","    x = tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","\n","    # randomly adjust the brightness of the image\n","    x = tf.image.random_brightness(x, max_delta=0.2)\n","\n","    # randomly adjust the contrast of the image\n","    x = tf.image.random_contrast(x, lower=0.2, upper=1.8)\n","\n","    x = RandomZoom(0.2)(x)\n","\n","    x = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=2, padding='same')(x) #layer-1\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.Activation('relu')(x)\n","    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n","\n","    filters = 64 #layer 2-5\n","    x = residual_block(x, filters,stride=1)\n","    x = residual_block(x, filters,stride=1)\n","\n","    if(x1==1):\n","      x=tf.keras.layers.Dropout(dr)(x)\n","\n","    filters *= 2 #layer 6-9\n","    downsample = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=2, padding='same')\n","    x = residual_block(x, filters, stride=2,downsample=downsample)\n","    x = residual_block(x, filters,stride=1)\n","\n","    if(x2==1):\n","      x=tf.keras.layers.Dropout(dr)(x)\n","\n","    filters *= 2 #layer 10-13\n","    downsample = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=2, padding='same')\n","    x = residual_block(x, filters, stride=2, downsample=downsample)\n","    x = residual_block(x, filters,stride=1)\n","\n","    if(x3==1):\n","      x=tf.keras.layers.Dropout(dr)(x)\n","\n","    filters *= 2 #layer 14-17\n","    downsample = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=2, padding='same')\n","    x = residual_block(x, filters, stride=2, downsample=downsample)\n","    x = residual_block(x, filters,stride=1)\n","\n","    if(x4==1):\n","      x=tf.keras.layers.Dropout(dr)(x)\n","\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    output_tensor = tf.keras.layers.Dense(num_classes, activation='softmax')(x) #layer-18\n","\n","    model = tf.keras.models.Model(input_tensor, output_tensor)\n","\n","    return model\n","\n","\n","\n","    "]},{"cell_type":"code","execution_count":16,"metadata":{"id":"czueQsI-cCII","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0a026597-267f-4c72-a5b0-8f4cf6c42e77","executionInfo":{"status":"ok","timestamp":1678900211301,"user_tz":-330,"elapsed":4637286,"user":{"displayName":"surya sai","userId":"02542796707014091485"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["131/131 [==============================] - 26s 92ms/step - loss: 2.7148 - accuracy: 0.1654 - val_loss: 2.2846 - val_accuracy: 0.1355\n","Epoch 2/100\n","131/131 [==============================] - 11s 87ms/step - loss: 2.1726 - accuracy: 0.2664 - val_loss: 2.2040 - val_accuracy: 0.1823\n","Epoch 3/100\n","131/131 [==============================] - 13s 97ms/step - loss: 1.9958 - accuracy: 0.3036 - val_loss: 1.9710 - val_accuracy: 0.2794\n","Epoch 4/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.8516 - accuracy: 0.3584 - val_loss: 1.9190 - val_accuracy: 0.3165\n","Epoch 5/100\n","131/131 [==============================] - 11s 82ms/step - loss: 1.7706 - accuracy: 0.3855 - val_loss: 1.9096 - val_accuracy: 0.3213\n","Epoch 6/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.7000 - accuracy: 0.4023 - val_loss: 1.8958 - val_accuracy: 0.3321\n","Epoch 7/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.6316 - accuracy: 0.4213 - val_loss: 1.8815 - val_accuracy: 0.3417\n","Epoch 8/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.5800 - accuracy: 0.4352 - val_loss: 1.8329 - val_accuracy: 0.3609\n","Epoch 9/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.5482 - accuracy: 0.4501 - val_loss: 1.8526 - val_accuracy: 0.3669\n","Epoch 10/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.4976 - accuracy: 0.4638 - val_loss: 1.8437 - val_accuracy: 0.3573\n","Epoch 11/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4424 - accuracy: 0.4926 - val_loss: 1.8096 - val_accuracy: 0.3609\n","Epoch 12/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.4147 - accuracy: 0.4911 - val_loss: 1.8004 - val_accuracy: 0.3717\n","Epoch 13/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.3795 - accuracy: 0.5139 - val_loss: 1.7912 - val_accuracy: 0.3861\n","Epoch 14/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.3355 - accuracy: 0.5264 - val_loss: 1.7556 - val_accuracy: 0.3825\n","Epoch 15/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.3037 - accuracy: 0.5427 - val_loss: 1.7740 - val_accuracy: 0.3825\n","Epoch 16/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.2620 - accuracy: 0.5581 - val_loss: 1.7914 - val_accuracy: 0.3717\n","Epoch 17/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.2416 - accuracy: 0.5651 - val_loss: 1.7423 - val_accuracy: 0.3957\n","Epoch 18/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.2027 - accuracy: 0.5809 - val_loss: 1.8017 - val_accuracy: 0.3909\n","Epoch 19/100\n","131/131 [==============================] - 11s 82ms/step - loss: 1.1607 - accuracy: 0.5927 - val_loss: 1.7869 - val_accuracy: 0.4089\n","Epoch 20/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.1489 - accuracy: 0.5883 - val_loss: 1.7668 - val_accuracy: 0.4017\n","Epoch 21/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.1075 - accuracy: 0.6164 - val_loss: 1.7913 - val_accuracy: 0.4017\n","Epoch 22/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.0674 - accuracy: 0.6323 - val_loss: 1.7912 - val_accuracy: 0.3993\n","Epoch 23/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.0536 - accuracy: 0.6330 - val_loss: 1.7554 - val_accuracy: 0.4185\n","Epoch 24/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0429 - accuracy: 0.6447 - val_loss: 1.7955 - val_accuracy: 0.3873\n","Epoch 25/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.9989 - accuracy: 0.6579 - val_loss: 1.7708 - val_accuracy: 0.4137\n","Epoch 26/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.9574 - accuracy: 0.6690 - val_loss: 1.7872 - val_accuracy: 0.3933\n","Epoch 27/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.9327 - accuracy: 0.6822 - val_loss: 1.7615 - val_accuracy: 0.4149\n","Epoch 28/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.9121 - accuracy: 0.6872 - val_loss: 1.8600 - val_accuracy: 0.3981\n","Epoch 29/100\n","131/131 [==============================] - 11s 88ms/step - loss: 0.8906 - accuracy: 0.6964 - val_loss: 1.7789 - val_accuracy: 0.4101\n","Epoch 30/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.8759 - accuracy: 0.7060 - val_loss: 1.8003 - val_accuracy: 0.3969\n","Epoch 31/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.8545 - accuracy: 0.7038 - val_loss: 1.8718 - val_accuracy: 0.3993\n","Epoch 32/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.8112 - accuracy: 0.7285 - val_loss: 1.8497 - val_accuracy: 0.4017\n","Epoch 33/100\n","131/131 [==============================] - 11s 82ms/step - loss: 0.8228 - accuracy: 0.7244 - val_loss: 1.8800 - val_accuracy: 0.4005\n","Epoch 34/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.7489 - accuracy: 0.7518 - val_loss: 1.8303 - val_accuracy: 0.4017\n","Epoch 35/100\n","131/131 [==============================] - 11s 88ms/step - loss: 0.7597 - accuracy: 0.7415 - val_loss: 1.7801 - val_accuracy: 0.4305\n","Epoch 36/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.7341 - accuracy: 0.7636 - val_loss: 1.8584 - val_accuracy: 0.4017\n","Epoch 37/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.7317 - accuracy: 0.7508 - val_loss: 1.8749 - val_accuracy: 0.4041\n","Epoch 38/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.6975 - accuracy: 0.7619 - val_loss: 1.8975 - val_accuracy: 0.4173\n","Epoch 39/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.6860 - accuracy: 0.7758 - val_loss: 1.8854 - val_accuracy: 0.4017\n","Epoch 40/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.6530 - accuracy: 0.7780 - val_loss: 1.8955 - val_accuracy: 0.4185\n","Epoch 41/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.6444 - accuracy: 0.7871 - val_loss: 1.8714 - val_accuracy: 0.4161\n","Epoch 42/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.6275 - accuracy: 0.7926 - val_loss: 1.8989 - val_accuracy: 0.4137\n","Epoch 43/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.6068 - accuracy: 0.7962 - val_loss: 1.8607 - val_accuracy: 0.4149\n","Epoch 44/100\n","131/131 [==============================] - 11s 88ms/step - loss: 0.5732 - accuracy: 0.8118 - val_loss: 1.9155 - val_accuracy: 0.3993\n","Epoch 45/100\n","131/131 [==============================] - 11s 88ms/step - loss: 0.5392 - accuracy: 0.8329 - val_loss: 1.9827 - val_accuracy: 0.3993\n","Epoch 46/100\n","131/131 [==============================] - 11s 83ms/step - loss: 0.5662 - accuracy: 0.8113 - val_loss: 1.9153 - val_accuracy: 0.4305\n","Epoch 47/100\n","131/131 [==============================] - 11s 82ms/step - loss: 0.5452 - accuracy: 0.8202 - val_loss: 1.9036 - val_accuracy: 0.4293\n","Epoch 48/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.5302 - accuracy: 0.8317 - val_loss: 2.0097 - val_accuracy: 0.4245\n","Epoch 49/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.5119 - accuracy: 0.8356 - val_loss: 1.9096 - val_accuracy: 0.4293\n","Epoch 50/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.4799 - accuracy: 0.8507 - val_loss: 1.9141 - val_accuracy: 0.4077\n","Epoch 51/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.4670 - accuracy: 0.8459 - val_loss: 1.9872 - val_accuracy: 0.4125\n","Epoch 52/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.4654 - accuracy: 0.8565 - val_loss: 2.0506 - val_accuracy: 0.4113\n","Epoch 53/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.4613 - accuracy: 0.8500 - val_loss: 1.9426 - val_accuracy: 0.4185\n","Epoch 54/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.4486 - accuracy: 0.8565 - val_loss: 2.0034 - val_accuracy: 0.4125\n","Epoch 55/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.4462 - accuracy: 0.8524 - val_loss: 2.0516 - val_accuracy: 0.4233\n","Epoch 56/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.4170 - accuracy: 0.8670 - val_loss: 2.0392 - val_accuracy: 0.4209\n","Epoch 57/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.4043 - accuracy: 0.8689 - val_loss: 2.0192 - val_accuracy: 0.4221\n","Epoch 58/100\n","131/131 [==============================] - 11s 83ms/step - loss: 0.3944 - accuracy: 0.8773 - val_loss: 1.9861 - val_accuracy: 0.4305\n","Epoch 59/100\n","131/131 [==============================] - 11s 81ms/step - loss: 0.3651 - accuracy: 0.8869 - val_loss: 2.0488 - val_accuracy: 0.4257\n","Epoch 60/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.3694 - accuracy: 0.8874 - val_loss: 2.0765 - val_accuracy: 0.4161\n","Epoch 61/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.3791 - accuracy: 0.8817 - val_loss: 2.0611 - val_accuracy: 0.4293\n","Epoch 62/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.3508 - accuracy: 0.8881 - val_loss: 2.0856 - val_accuracy: 0.4388\n","Epoch 63/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.3557 - accuracy: 0.8879 - val_loss: 2.1609 - val_accuracy: 0.4065\n","Epoch 64/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.3369 - accuracy: 0.8956 - val_loss: 2.1357 - val_accuracy: 0.4269\n","Epoch 65/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.3250 - accuracy: 0.9023 - val_loss: 2.1074 - val_accuracy: 0.4269\n","Epoch 66/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.2989 - accuracy: 0.9054 - val_loss: 2.1363 - val_accuracy: 0.4125\n","Epoch 67/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.3184 - accuracy: 0.9009 - val_loss: 2.2273 - val_accuracy: 0.4269\n","Epoch 68/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.2812 - accuracy: 0.9169 - val_loss: 2.1455 - val_accuracy: 0.4400\n","Epoch 69/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.2777 - accuracy: 0.9141 - val_loss: 2.1675 - val_accuracy: 0.4269\n","Epoch 70/100\n","131/131 [==============================] - 11s 81ms/step - loss: 0.3064 - accuracy: 0.9037 - val_loss: 2.1205 - val_accuracy: 0.4269\n","Epoch 71/100\n","131/131 [==============================] - 11s 81ms/step - loss: 0.2994 - accuracy: 0.9054 - val_loss: 2.1519 - val_accuracy: 0.4293\n","Epoch 72/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.2790 - accuracy: 0.9143 - val_loss: 2.1595 - val_accuracy: 0.4233\n","Epoch 73/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.2831 - accuracy: 0.9121 - val_loss: 2.1395 - val_accuracy: 0.4388\n","Epoch 74/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.2740 - accuracy: 0.9150 - val_loss: 2.3077 - val_accuracy: 0.4065\n","Epoch 75/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.2649 - accuracy: 0.9157 - val_loss: 2.2384 - val_accuracy: 0.4317\n","Epoch 76/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.2358 - accuracy: 0.9297 - val_loss: 2.2563 - val_accuracy: 0.4137\n","Epoch 77/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.2403 - accuracy: 0.9265 - val_loss: 2.2231 - val_accuracy: 0.4269\n","Epoch 78/100\n","131/131 [==============================] - 11s 88ms/step - loss: 0.2372 - accuracy: 0.9277 - val_loss: 2.2656 - val_accuracy: 0.4149\n","Epoch 79/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.2437 - accuracy: 0.9282 - val_loss: 2.2220 - val_accuracy: 0.4412\n","Epoch 80/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.2418 - accuracy: 0.9225 - val_loss: 2.1978 - val_accuracy: 0.4329\n","Epoch 81/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.2317 - accuracy: 0.9299 - val_loss: 2.2233 - val_accuracy: 0.4305\n","Epoch 82/100\n","131/131 [==============================] - 11s 81ms/step - loss: 0.2245 - accuracy: 0.9277 - val_loss: 2.2763 - val_accuracy: 0.4221\n","Epoch 83/100\n","131/131 [==============================] - 11s 83ms/step - loss: 0.2092 - accuracy: 0.9364 - val_loss: 2.2780 - val_accuracy: 0.4245\n","Epoch 84/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.2207 - accuracy: 0.9337 - val_loss: 2.3314 - val_accuracy: 0.4197\n","Epoch 85/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.1890 - accuracy: 0.9426 - val_loss: 2.2524 - val_accuracy: 0.4376\n","Epoch 86/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.1932 - accuracy: 0.9398 - val_loss: 2.2456 - val_accuracy: 0.4305\n","Epoch 87/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.1988 - accuracy: 0.9417 - val_loss: 2.2812 - val_accuracy: 0.4281\n","Epoch 88/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.1816 - accuracy: 0.9443 - val_loss: 2.2908 - val_accuracy: 0.4448\n","Epoch 89/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.1882 - accuracy: 0.9393 - val_loss: 2.3261 - val_accuracy: 0.4173\n","Epoch 90/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.1923 - accuracy: 0.9412 - val_loss: 2.3780 - val_accuracy: 0.4281\n","Epoch 91/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.1696 - accuracy: 0.9506 - val_loss: 2.2986 - val_accuracy: 0.4197\n","Epoch 92/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.1690 - accuracy: 0.9510 - val_loss: 2.4135 - val_accuracy: 0.4412\n","Epoch 93/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.1734 - accuracy: 0.9489 - val_loss: 2.3965 - val_accuracy: 0.4185\n","Epoch 94/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.1849 - accuracy: 0.9429 - val_loss: 2.3615 - val_accuracy: 0.4365\n","Epoch 95/100\n","131/131 [==============================] - 11s 82ms/step - loss: 0.1733 - accuracy: 0.9450 - val_loss: 2.3496 - val_accuracy: 0.4388\n","Epoch 96/100\n","131/131 [==============================] - 11s 83ms/step - loss: 0.1714 - accuracy: 0.9486 - val_loss: 2.3303 - val_accuracy: 0.4233\n","Epoch 97/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.1652 - accuracy: 0.9479 - val_loss: 2.3732 - val_accuracy: 0.4281\n","Epoch 98/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.1569 - accuracy: 0.9515 - val_loss: 2.3526 - val_accuracy: 0.4305\n","Epoch 99/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.1552 - accuracy: 0.9554 - val_loss: 2.4736 - val_accuracy: 0.4329\n","Epoch 100/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.1593 - accuracy: 0.9525 - val_loss: 2.3273 - val_accuracy: 0.4269\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["131/131 [==============================] - 24s 90ms/step - loss: 2.9107 - accuracy: 0.1447 - val_loss: 2.3161 - val_accuracy: 0.1019\n","Epoch 2/100\n","131/131 [==============================] - 11s 81ms/step - loss: 2.3847 - accuracy: 0.2225 - val_loss: 2.2413 - val_accuracy: 0.1475\n","Epoch 3/100\n","131/131 [==============================] - 11s 83ms/step - loss: 2.2036 - accuracy: 0.2549 - val_loss: 2.0485 - val_accuracy: 0.2530\n","Epoch 4/100\n","131/131 [==============================] - 11s 87ms/step - loss: 2.0790 - accuracy: 0.2847 - val_loss: 2.0133 - val_accuracy: 0.2938\n","Epoch 5/100\n","131/131 [==============================] - 11s 85ms/step - loss: 2.0438 - accuracy: 0.3048 - val_loss: 1.9553 - val_accuracy: 0.3249\n","Epoch 6/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.9457 - accuracy: 0.3217 - val_loss: 1.9053 - val_accuracy: 0.3609\n","Epoch 7/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.9108 - accuracy: 0.3279 - val_loss: 1.9579 - val_accuracy: 0.3213\n","Epoch 8/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.8686 - accuracy: 0.3433 - val_loss: 1.9349 - val_accuracy: 0.3417\n","Epoch 9/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.8273 - accuracy: 0.3493 - val_loss: 1.8943 - val_accuracy: 0.3489\n","Epoch 10/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.7813 - accuracy: 0.3680 - val_loss: 1.8428 - val_accuracy: 0.3645\n","Epoch 11/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.7320 - accuracy: 0.3913 - val_loss: 1.8321 - val_accuracy: 0.3609\n","Epoch 12/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.6877 - accuracy: 0.4071 - val_loss: 1.8468 - val_accuracy: 0.3741\n","Epoch 13/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.6863 - accuracy: 0.4040 - val_loss: 1.8118 - val_accuracy: 0.3825\n","Epoch 14/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.6496 - accuracy: 0.4052 - val_loss: 1.8182 - val_accuracy: 0.3729\n","Epoch 15/100\n","131/131 [==============================] - 11s 80ms/step - loss: 1.6179 - accuracy: 0.4191 - val_loss: 1.7937 - val_accuracy: 0.3861\n","Epoch 16/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.6022 - accuracy: 0.4313 - val_loss: 1.7821 - val_accuracy: 0.3933\n","Epoch 17/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.5893 - accuracy: 0.4246 - val_loss: 1.7640 - val_accuracy: 0.3837\n","Epoch 18/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.5584 - accuracy: 0.4438 - val_loss: 1.7547 - val_accuracy: 0.3801\n","Epoch 19/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.5444 - accuracy: 0.4465 - val_loss: 1.7653 - val_accuracy: 0.3873\n","Epoch 20/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.5013 - accuracy: 0.4578 - val_loss: 1.7410 - val_accuracy: 0.3921\n","Epoch 21/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.4691 - accuracy: 0.4772 - val_loss: 1.7221 - val_accuracy: 0.4041\n","Epoch 22/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.4831 - accuracy: 0.4642 - val_loss: 1.6921 - val_accuracy: 0.4005\n","Epoch 23/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.4425 - accuracy: 0.4803 - val_loss: 1.7077 - val_accuracy: 0.4005\n","Epoch 24/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.4406 - accuracy: 0.4820 - val_loss: 1.7112 - val_accuracy: 0.3945\n","Epoch 25/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.4240 - accuracy: 0.4878 - val_loss: 1.6737 - val_accuracy: 0.3909\n","Epoch 26/100\n","131/131 [==============================] - 11s 81ms/step - loss: 1.3950 - accuracy: 0.4933 - val_loss: 1.6752 - val_accuracy: 0.4221\n","Epoch 27/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.3995 - accuracy: 0.4959 - val_loss: 1.6787 - val_accuracy: 0.4101\n","Epoch 28/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.3489 - accuracy: 0.5269 - val_loss: 1.6966 - val_accuracy: 0.4077\n","Epoch 29/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.3388 - accuracy: 0.5252 - val_loss: 1.6707 - val_accuracy: 0.4065\n","Epoch 30/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.3482 - accuracy: 0.5211 - val_loss: 1.6824 - val_accuracy: 0.4101\n","Epoch 31/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.2995 - accuracy: 0.5403 - val_loss: 1.6355 - val_accuracy: 0.4329\n","Epoch 32/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.3080 - accuracy: 0.5343 - val_loss: 1.6172 - val_accuracy: 0.4293\n","Epoch 33/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.2792 - accuracy: 0.5511 - val_loss: 1.6266 - val_accuracy: 0.4281\n","Epoch 34/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.2824 - accuracy: 0.5410 - val_loss: 1.6442 - val_accuracy: 0.4209\n","Epoch 35/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.2407 - accuracy: 0.5509 - val_loss: 1.6228 - val_accuracy: 0.4532\n","Epoch 36/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.2318 - accuracy: 0.5641 - val_loss: 1.5940 - val_accuracy: 0.4604\n","Epoch 37/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.2154 - accuracy: 0.5687 - val_loss: 1.6174 - val_accuracy: 0.4412\n","Epoch 38/100\n","131/131 [==============================] - 11s 80ms/step - loss: 1.2152 - accuracy: 0.5706 - val_loss: 1.5932 - val_accuracy: 0.4580\n","Epoch 39/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.2167 - accuracy: 0.5658 - val_loss: 1.5856 - val_accuracy: 0.4460\n","Epoch 40/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.1690 - accuracy: 0.5816 - val_loss: 1.5997 - val_accuracy: 0.4341\n","Epoch 41/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.1592 - accuracy: 0.5859 - val_loss: 1.6195 - val_accuracy: 0.4544\n","Epoch 42/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.1397 - accuracy: 0.5867 - val_loss: 1.5792 - val_accuracy: 0.4568\n","Epoch 43/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.1321 - accuracy: 0.5927 - val_loss: 1.6073 - val_accuracy: 0.4400\n","Epoch 44/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.1241 - accuracy: 0.5999 - val_loss: 1.6104 - val_accuracy: 0.4305\n","Epoch 45/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0975 - accuracy: 0.6039 - val_loss: 1.6101 - val_accuracy: 0.4388\n","Epoch 46/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0881 - accuracy: 0.6044 - val_loss: 1.6096 - val_accuracy: 0.4640\n","Epoch 47/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0948 - accuracy: 0.6080 - val_loss: 1.5808 - val_accuracy: 0.4556\n","Epoch 48/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.0782 - accuracy: 0.6119 - val_loss: 1.6286 - val_accuracy: 0.4376\n","Epoch 49/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.0526 - accuracy: 0.6306 - val_loss: 1.6333 - val_accuracy: 0.4341\n","Epoch 50/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.0540 - accuracy: 0.6200 - val_loss: 1.6337 - val_accuracy: 0.4376\n","Epoch 51/100\n","131/131 [==============================] - 11s 82ms/step - loss: 1.0339 - accuracy: 0.6212 - val_loss: 1.5954 - val_accuracy: 0.4544\n","Epoch 52/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.0087 - accuracy: 0.6455 - val_loss: 1.6105 - val_accuracy: 0.4604\n","Epoch 53/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0108 - accuracy: 0.6447 - val_loss: 1.6249 - val_accuracy: 0.4532\n","Epoch 54/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.9852 - accuracy: 0.6474 - val_loss: 1.6065 - val_accuracy: 0.4640\n","Epoch 55/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.9768 - accuracy: 0.6553 - val_loss: 1.5611 - val_accuracy: 0.4676\n","Epoch 56/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.9571 - accuracy: 0.6575 - val_loss: 1.6033 - val_accuracy: 0.4616\n","Epoch 57/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.9446 - accuracy: 0.6656 - val_loss: 1.5891 - val_accuracy: 0.4664\n","Epoch 58/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.9488 - accuracy: 0.6661 - val_loss: 1.6134 - val_accuracy: 0.4508\n","Epoch 59/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.9583 - accuracy: 0.6534 - val_loss: 1.6013 - val_accuracy: 0.4760\n","Epoch 60/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.9182 - accuracy: 0.6719 - val_loss: 1.5971 - val_accuracy: 0.4808\n","Epoch 61/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.9097 - accuracy: 0.6889 - val_loss: 1.5864 - val_accuracy: 0.4760\n","Epoch 62/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.8965 - accuracy: 0.6834 - val_loss: 1.6060 - val_accuracy: 0.4520\n","Epoch 63/100\n","131/131 [==============================] - 11s 84ms/step - loss: 0.9155 - accuracy: 0.6716 - val_loss: 1.5857 - val_accuracy: 0.4820\n","Epoch 64/100\n","131/131 [==============================] - 11s 82ms/step - loss: 0.8678 - accuracy: 0.6959 - val_loss: 1.6771 - val_accuracy: 0.4544\n","Epoch 65/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.8630 - accuracy: 0.7055 - val_loss: 1.6136 - val_accuracy: 0.4520\n","Epoch 66/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.8478 - accuracy: 0.6954 - val_loss: 1.6202 - val_accuracy: 0.4844\n","Epoch 67/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.8504 - accuracy: 0.6968 - val_loss: 1.5996 - val_accuracy: 0.4916\n","Epoch 68/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.8197 - accuracy: 0.7096 - val_loss: 1.5931 - val_accuracy: 0.4724\n","Epoch 69/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.8263 - accuracy: 0.7132 - val_loss: 1.6037 - val_accuracy: 0.4760\n","Epoch 70/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.8183 - accuracy: 0.7160 - val_loss: 1.6171 - val_accuracy: 0.4700\n","Epoch 71/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.7984 - accuracy: 0.7201 - val_loss: 1.6240 - val_accuracy: 0.4748\n","Epoch 72/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.7797 - accuracy: 0.7266 - val_loss: 1.6242 - val_accuracy: 0.4592\n","Epoch 73/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.7949 - accuracy: 0.7196 - val_loss: 1.6463 - val_accuracy: 0.4676\n","Epoch 74/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.7490 - accuracy: 0.7403 - val_loss: 1.6084 - val_accuracy: 0.4640\n","Epoch 75/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.7419 - accuracy: 0.7384 - val_loss: 1.6397 - val_accuracy: 0.4736\n","Epoch 76/100\n","131/131 [==============================] - 11s 82ms/step - loss: 0.7388 - accuracy: 0.7460 - val_loss: 1.6634 - val_accuracy: 0.4676\n","Epoch 77/100\n","131/131 [==============================] - 11s 81ms/step - loss: 0.7475 - accuracy: 0.7364 - val_loss: 1.5852 - val_accuracy: 0.4652\n","Epoch 78/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.7138 - accuracy: 0.7506 - val_loss: 1.6870 - val_accuracy: 0.4832\n","Epoch 79/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.7272 - accuracy: 0.7504 - val_loss: 1.6408 - val_accuracy: 0.4892\n","Epoch 80/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.7256 - accuracy: 0.7525 - val_loss: 1.6650 - val_accuracy: 0.4736\n","Epoch 81/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.6966 - accuracy: 0.7540 - val_loss: 1.6803 - val_accuracy: 0.4736\n","Epoch 82/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.6948 - accuracy: 0.7597 - val_loss: 1.6968 - val_accuracy: 0.4784\n","Epoch 83/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.7037 - accuracy: 0.7492 - val_loss: 1.6241 - val_accuracy: 0.4748\n","Epoch 84/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.6493 - accuracy: 0.7746 - val_loss: 1.6611 - val_accuracy: 0.4580\n","Epoch 85/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.6444 - accuracy: 0.7748 - val_loss: 1.6670 - val_accuracy: 0.4700\n","Epoch 86/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.6677 - accuracy: 0.7640 - val_loss: 1.6308 - val_accuracy: 0.4784\n","Epoch 87/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.6323 - accuracy: 0.7804 - val_loss: 1.6517 - val_accuracy: 0.4832\n","Epoch 88/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.6138 - accuracy: 0.7852 - val_loss: 1.6940 - val_accuracy: 0.4724\n","Epoch 89/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.6088 - accuracy: 0.7854 - val_loss: 1.6470 - val_accuracy: 0.4736\n","Epoch 90/100\n","131/131 [==============================] - 11s 83ms/step - loss: 0.6324 - accuracy: 0.7825 - val_loss: 1.6856 - val_accuracy: 0.4880\n","Epoch 91/100\n","131/131 [==============================] - 11s 82ms/step - loss: 0.6053 - accuracy: 0.7832 - val_loss: 1.6751 - val_accuracy: 0.4724\n","Epoch 92/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.5784 - accuracy: 0.7981 - val_loss: 1.6999 - val_accuracy: 0.4676\n","Epoch 93/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.5697 - accuracy: 0.8075 - val_loss: 1.7003 - val_accuracy: 0.4892\n","Epoch 94/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.5680 - accuracy: 0.8082 - val_loss: 1.7453 - val_accuracy: 0.4580\n","Epoch 95/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.5621 - accuracy: 0.8094 - val_loss: 1.6931 - val_accuracy: 0.4628\n","Epoch 96/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.5686 - accuracy: 0.8092 - val_loss: 1.7603 - val_accuracy: 0.4688\n","Epoch 97/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.5655 - accuracy: 0.8008 - val_loss: 1.7556 - val_accuracy: 0.4772\n","Epoch 98/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.5141 - accuracy: 0.8243 - val_loss: 1.7064 - val_accuracy: 0.4820\n","Epoch 99/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.5440 - accuracy: 0.8140 - val_loss: 1.6656 - val_accuracy: 0.4688\n","Epoch 100/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.5349 - accuracy: 0.8133 - val_loss: 1.7278 - val_accuracy: 0.4844\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["131/131 [==============================] - 24s 91ms/step - loss: 2.8051 - accuracy: 0.1445 - val_loss: 2.2844 - val_accuracy: 0.1307\n","Epoch 2/100\n","131/131 [==============================] - 11s 86ms/step - loss: 2.4753 - accuracy: 0.1923 - val_loss: 2.2072 - val_accuracy: 0.1811\n","Epoch 3/100\n","131/131 [==============================] - 11s 86ms/step - loss: 2.3282 - accuracy: 0.2266 - val_loss: 2.0789 - val_accuracy: 0.2314\n","Epoch 4/100\n","131/131 [==============================] - 11s 84ms/step - loss: 2.2140 - accuracy: 0.2470 - val_loss: 2.0604 - val_accuracy: 0.2518\n","Epoch 5/100\n","131/131 [==============================] - 11s 83ms/step - loss: 2.1532 - accuracy: 0.2600 - val_loss: 2.0029 - val_accuracy: 0.2710\n","Epoch 6/100\n","131/131 [==============================] - 11s 82ms/step - loss: 2.0825 - accuracy: 0.2804 - val_loss: 1.9569 - val_accuracy: 0.3118\n","Epoch 7/100\n","131/131 [==============================] - 11s 84ms/step - loss: 2.0270 - accuracy: 0.2957 - val_loss: 1.9583 - val_accuracy: 0.2950\n","Epoch 8/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.9980 - accuracy: 0.2993 - val_loss: 1.9057 - val_accuracy: 0.3189\n","Epoch 9/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.9917 - accuracy: 0.3046 - val_loss: 1.8989 - val_accuracy: 0.3249\n","Epoch 10/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.9630 - accuracy: 0.3159 - val_loss: 1.8809 - val_accuracy: 0.3261\n","Epoch 11/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.8824 - accuracy: 0.3375 - val_loss: 1.8499 - val_accuracy: 0.3333\n","Epoch 12/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.8671 - accuracy: 0.3320 - val_loss: 1.8287 - val_accuracy: 0.3405\n","Epoch 13/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.8440 - accuracy: 0.3341 - val_loss: 1.8406 - val_accuracy: 0.3405\n","Epoch 14/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.8162 - accuracy: 0.3423 - val_loss: 1.8158 - val_accuracy: 0.3477\n","Epoch 15/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.8213 - accuracy: 0.3526 - val_loss: 1.7673 - val_accuracy: 0.3513\n","Epoch 16/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.7849 - accuracy: 0.3531 - val_loss: 1.7739 - val_accuracy: 0.3549\n","Epoch 17/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.7482 - accuracy: 0.3771 - val_loss: 1.7143 - val_accuracy: 0.3657\n","Epoch 18/100\n","131/131 [==============================] - 11s 81ms/step - loss: 1.7520 - accuracy: 0.3773 - val_loss: 1.7391 - val_accuracy: 0.3621\n","Epoch 19/100\n","131/131 [==============================] - 11s 81ms/step - loss: 1.7204 - accuracy: 0.3829 - val_loss: 1.7509 - val_accuracy: 0.3717\n","Epoch 20/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.7276 - accuracy: 0.3812 - val_loss: 1.7046 - val_accuracy: 0.3933\n","Epoch 21/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.6927 - accuracy: 0.3925 - val_loss: 1.6911 - val_accuracy: 0.3885\n","Epoch 22/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.6852 - accuracy: 0.3910 - val_loss: 1.6907 - val_accuracy: 0.3909\n","Epoch 23/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.6712 - accuracy: 0.4037 - val_loss: 1.6585 - val_accuracy: 0.4029\n","Epoch 24/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.6750 - accuracy: 0.3953 - val_loss: 1.6858 - val_accuracy: 0.3849\n","Epoch 25/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.6516 - accuracy: 0.4023 - val_loss: 1.6692 - val_accuracy: 0.3897\n","Epoch 26/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.6356 - accuracy: 0.4093 - val_loss: 1.6489 - val_accuracy: 0.4101\n","Epoch 27/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.6288 - accuracy: 0.4181 - val_loss: 1.6480 - val_accuracy: 0.3909\n","Epoch 28/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.6052 - accuracy: 0.4292 - val_loss: 1.6585 - val_accuracy: 0.4125\n","Epoch 29/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.6066 - accuracy: 0.4205 - val_loss: 1.6307 - val_accuracy: 0.4161\n","Epoch 30/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.5745 - accuracy: 0.4249 - val_loss: 1.6235 - val_accuracy: 0.4077\n","Epoch 31/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.5737 - accuracy: 0.4277 - val_loss: 1.6134 - val_accuracy: 0.4209\n","Epoch 32/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5580 - accuracy: 0.4316 - val_loss: 1.6179 - val_accuracy: 0.4089\n","Epoch 33/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5494 - accuracy: 0.4378 - val_loss: 1.6111 - val_accuracy: 0.4161\n","Epoch 34/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.5299 - accuracy: 0.4414 - val_loss: 1.6154 - val_accuracy: 0.4089\n","Epoch 35/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.4999 - accuracy: 0.4642 - val_loss: 1.5839 - val_accuracy: 0.4317\n","Epoch 36/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4863 - accuracy: 0.4604 - val_loss: 1.5749 - val_accuracy: 0.4412\n","Epoch 37/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4936 - accuracy: 0.4506 - val_loss: 1.5665 - val_accuracy: 0.4185\n","Epoch 38/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.4596 - accuracy: 0.4635 - val_loss: 1.5725 - val_accuracy: 0.4412\n","Epoch 39/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.5000 - accuracy: 0.4534 - val_loss: 1.5586 - val_accuracy: 0.4388\n","Epoch 40/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.4816 - accuracy: 0.4563 - val_loss: 1.5347 - val_accuracy: 0.4365\n","Epoch 41/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4773 - accuracy: 0.4707 - val_loss: 1.5413 - val_accuracy: 0.4424\n","Epoch 42/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.4298 - accuracy: 0.4746 - val_loss: 1.5505 - val_accuracy: 0.4329\n","Epoch 43/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.4525 - accuracy: 0.4748 - val_loss: 1.5662 - val_accuracy: 0.4257\n","Epoch 44/100\n","131/131 [==============================] - 11s 82ms/step - loss: 1.4221 - accuracy: 0.4786 - val_loss: 1.5246 - val_accuracy: 0.4448\n","Epoch 45/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.4254 - accuracy: 0.4796 - val_loss: 1.5473 - val_accuracy: 0.4269\n","Epoch 46/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3939 - accuracy: 0.4918 - val_loss: 1.5464 - val_accuracy: 0.4353\n","Epoch 47/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3946 - accuracy: 0.4950 - val_loss: 1.5063 - val_accuracy: 0.4640\n","Epoch 48/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.3769 - accuracy: 0.4986 - val_loss: 1.5326 - val_accuracy: 0.4472\n","Epoch 49/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3931 - accuracy: 0.4959 - val_loss: 1.5269 - val_accuracy: 0.4484\n","Epoch 50/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.3592 - accuracy: 0.5127 - val_loss: 1.5190 - val_accuracy: 0.4736\n","Epoch 51/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.3800 - accuracy: 0.5010 - val_loss: 1.5183 - val_accuracy: 0.4544\n","Epoch 52/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.3423 - accuracy: 0.5053 - val_loss: 1.5231 - val_accuracy: 0.4460\n","Epoch 53/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.3280 - accuracy: 0.5168 - val_loss: 1.4973 - val_accuracy: 0.4580\n","Epoch 54/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3466 - accuracy: 0.5130 - val_loss: 1.5155 - val_accuracy: 0.4748\n","Epoch 55/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.3077 - accuracy: 0.5226 - val_loss: 1.5325 - val_accuracy: 0.4520\n","Epoch 56/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.3138 - accuracy: 0.5322 - val_loss: 1.5207 - val_accuracy: 0.4640\n","Epoch 57/100\n","131/131 [==============================] - 11s 82ms/step - loss: 1.3164 - accuracy: 0.5302 - val_loss: 1.5055 - val_accuracy: 0.4664\n","Epoch 58/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.3005 - accuracy: 0.5362 - val_loss: 1.5018 - val_accuracy: 0.4568\n","Epoch 59/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.2941 - accuracy: 0.5266 - val_loss: 1.4963 - val_accuracy: 0.4736\n","Epoch 60/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.2683 - accuracy: 0.5324 - val_loss: 1.4898 - val_accuracy: 0.4784\n","Epoch 61/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.2717 - accuracy: 0.5386 - val_loss: 1.4658 - val_accuracy: 0.4808\n","Epoch 62/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.2800 - accuracy: 0.5410 - val_loss: 1.4914 - val_accuracy: 0.4772\n","Epoch 63/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.2565 - accuracy: 0.5434 - val_loss: 1.4806 - val_accuracy: 0.4688\n","Epoch 64/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.2554 - accuracy: 0.5494 - val_loss: 1.4615 - val_accuracy: 0.4772\n","Epoch 65/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.2533 - accuracy: 0.5466 - val_loss: 1.4896 - val_accuracy: 0.4808\n","Epoch 66/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.2232 - accuracy: 0.5545 - val_loss: 1.4946 - val_accuracy: 0.4700\n","Epoch 67/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.2207 - accuracy: 0.5562 - val_loss: 1.4923 - val_accuracy: 0.4676\n","Epoch 68/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.2432 - accuracy: 0.5386 - val_loss: 1.5094 - val_accuracy: 0.4556\n","Epoch 69/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.2121 - accuracy: 0.5624 - val_loss: 1.4787 - val_accuracy: 0.4868\n","Epoch 70/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.2022 - accuracy: 0.5646 - val_loss: 1.4873 - val_accuracy: 0.4892\n","Epoch 71/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.1922 - accuracy: 0.5696 - val_loss: 1.4804 - val_accuracy: 0.4820\n","Epoch 72/100\n","131/131 [==============================] - 11s 81ms/step - loss: 1.1847 - accuracy: 0.5667 - val_loss: 1.4579 - val_accuracy: 0.4856\n","Epoch 73/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.1882 - accuracy: 0.5687 - val_loss: 1.4617 - val_accuracy: 0.4784\n","Epoch 74/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.1670 - accuracy: 0.5840 - val_loss: 1.4667 - val_accuracy: 0.4880\n","Epoch 75/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.1341 - accuracy: 0.5903 - val_loss: 1.4799 - val_accuracy: 0.4820\n","Epoch 76/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.1409 - accuracy: 0.5893 - val_loss: 1.4386 - val_accuracy: 0.5000\n","Epoch 77/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.1527 - accuracy: 0.5864 - val_loss: 1.4677 - val_accuracy: 0.4760\n","Epoch 78/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.1111 - accuracy: 0.5886 - val_loss: 1.4560 - val_accuracy: 0.4856\n","Epoch 79/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.1138 - accuracy: 0.5917 - val_loss: 1.4786 - val_accuracy: 0.4928\n","Epoch 80/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.1136 - accuracy: 0.6080 - val_loss: 1.4252 - val_accuracy: 0.4988\n","Epoch 81/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.1276 - accuracy: 0.5915 - val_loss: 1.4602 - val_accuracy: 0.4916\n","Epoch 82/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.1030 - accuracy: 0.6047 - val_loss: 1.4304 - val_accuracy: 0.5012\n","Epoch 83/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.1077 - accuracy: 0.6042 - val_loss: 1.4650 - val_accuracy: 0.4952\n","Epoch 84/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0837 - accuracy: 0.6090 - val_loss: 1.4264 - val_accuracy: 0.5024\n","Epoch 85/100\n","131/131 [==============================] - 11s 81ms/step - loss: 1.0914 - accuracy: 0.5982 - val_loss: 1.4628 - val_accuracy: 0.4940\n","Epoch 86/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.0759 - accuracy: 0.6114 - val_loss: 1.4716 - val_accuracy: 0.4868\n","Epoch 87/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.0713 - accuracy: 0.6191 - val_loss: 1.4713 - val_accuracy: 0.5024\n","Epoch 88/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0653 - accuracy: 0.6289 - val_loss: 1.4726 - val_accuracy: 0.4904\n","Epoch 89/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0675 - accuracy: 0.6087 - val_loss: 1.4691 - val_accuracy: 0.4928\n","Epoch 90/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.0232 - accuracy: 0.6279 - val_loss: 1.4546 - val_accuracy: 0.4892\n","Epoch 91/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.0414 - accuracy: 0.6265 - val_loss: 1.4293 - val_accuracy: 0.5024\n","Epoch 92/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.0056 - accuracy: 0.6363 - val_loss: 1.4691 - val_accuracy: 0.4904\n","Epoch 93/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0287 - accuracy: 0.6330 - val_loss: 1.4153 - val_accuracy: 0.5084\n","Epoch 94/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.0316 - accuracy: 0.6265 - val_loss: 1.4569 - val_accuracy: 0.4976\n","Epoch 95/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.0075 - accuracy: 0.6342 - val_loss: 1.4540 - val_accuracy: 0.4976\n","Epoch 96/100\n","131/131 [==============================] - 11s 85ms/step - loss: 0.9849 - accuracy: 0.6368 - val_loss: 1.4591 - val_accuracy: 0.4940\n","Epoch 97/100\n","131/131 [==============================] - 11s 86ms/step - loss: 0.9890 - accuracy: 0.6498 - val_loss: 1.4614 - val_accuracy: 0.5048\n","Epoch 98/100\n","131/131 [==============================] - 11s 82ms/step - loss: 0.9873 - accuracy: 0.6416 - val_loss: 1.4564 - val_accuracy: 0.5096\n","Epoch 99/100\n","131/131 [==============================] - 11s 82ms/step - loss: 0.9758 - accuracy: 0.6486 - val_loss: 1.4572 - val_accuracy: 0.4928\n","Epoch 100/100\n","131/131 [==============================] - 11s 87ms/step - loss: 0.9521 - accuracy: 0.6579 - val_loss: 1.4280 - val_accuracy: 0.5132\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["131/131 [==============================] - 26s 92ms/step - loss: 3.0024 - accuracy: 0.1258 - val_loss: 2.3094 - val_accuracy: 0.1283\n","Epoch 2/100\n","131/131 [==============================] - 11s 84ms/step - loss: 2.5975 - accuracy: 0.1623 - val_loss: 2.3178 - val_accuracy: 0.1427\n","Epoch 3/100\n","131/131 [==============================] - 11s 87ms/step - loss: 2.4151 - accuracy: 0.1935 - val_loss: 2.2953 - val_accuracy: 0.1775\n","Epoch 4/100\n","131/131 [==============================] - 11s 86ms/step - loss: 2.3565 - accuracy: 0.2002 - val_loss: 2.2354 - val_accuracy: 0.2086\n","Epoch 5/100\n","131/131 [==============================] - 11s 84ms/step - loss: 2.2765 - accuracy: 0.2206 - val_loss: 2.2179 - val_accuracy: 0.2194\n","Epoch 6/100\n","131/131 [==============================] - 11s 85ms/step - loss: 2.2109 - accuracy: 0.2285 - val_loss: 2.1886 - val_accuracy: 0.2362\n","Epoch 7/100\n","131/131 [==============================] - 11s 85ms/step - loss: 2.1997 - accuracy: 0.2420 - val_loss: 2.1629 - val_accuracy: 0.2446\n","Epoch 8/100\n","131/131 [==============================] - 11s 84ms/step - loss: 2.1392 - accuracy: 0.2477 - val_loss: 2.1532 - val_accuracy: 0.2518\n","Epoch 9/100\n","131/131 [==============================] - 10s 80ms/step - loss: 2.1149 - accuracy: 0.2566 - val_loss: 2.0862 - val_accuracy: 0.2650\n","Epoch 10/100\n","131/131 [==============================] - 11s 85ms/step - loss: 2.0971 - accuracy: 0.2600 - val_loss: 2.0741 - val_accuracy: 0.2530\n","Epoch 11/100\n","131/131 [==============================] - 11s 87ms/step - loss: 2.0475 - accuracy: 0.2830 - val_loss: 2.0708 - val_accuracy: 0.2662\n","Epoch 12/100\n","131/131 [==============================] - 11s 87ms/step - loss: 2.0492 - accuracy: 0.2787 - val_loss: 2.0289 - val_accuracy: 0.2866\n","Epoch 13/100\n","131/131 [==============================] - 11s 87ms/step - loss: 2.0117 - accuracy: 0.2926 - val_loss: 1.9957 - val_accuracy: 0.2962\n","Epoch 14/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.9819 - accuracy: 0.2957 - val_loss: 1.9706 - val_accuracy: 0.2890\n","Epoch 15/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.9442 - accuracy: 0.3060 - val_loss: 1.9840 - val_accuracy: 0.2926\n","Epoch 16/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.9864 - accuracy: 0.2871 - val_loss: 1.9147 - val_accuracy: 0.3058\n","Epoch 17/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.9195 - accuracy: 0.3099 - val_loss: 1.9007 - val_accuracy: 0.3094\n","Epoch 18/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.9062 - accuracy: 0.3171 - val_loss: 1.9232 - val_accuracy: 0.3070\n","Epoch 19/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.9088 - accuracy: 0.3087 - val_loss: 1.9149 - val_accuracy: 0.3153\n","Epoch 20/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.8855 - accuracy: 0.3253 - val_loss: 1.8824 - val_accuracy: 0.3261\n","Epoch 21/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.8656 - accuracy: 0.3274 - val_loss: 1.8465 - val_accuracy: 0.3309\n","Epoch 22/100\n","131/131 [==============================] - 11s 82ms/step - loss: 1.8283 - accuracy: 0.3382 - val_loss: 1.8377 - val_accuracy: 0.3201\n","Epoch 23/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.8458 - accuracy: 0.3293 - val_loss: 1.8226 - val_accuracy: 0.3513\n","Epoch 24/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.8198 - accuracy: 0.3399 - val_loss: 1.8302 - val_accuracy: 0.3345\n","Epoch 25/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.8151 - accuracy: 0.3454 - val_loss: 1.8166 - val_accuracy: 0.3309\n","Epoch 26/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.8150 - accuracy: 0.3437 - val_loss: 1.7808 - val_accuracy: 0.3465\n","Epoch 27/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.7877 - accuracy: 0.3565 - val_loss: 1.7820 - val_accuracy: 0.3393\n","Epoch 28/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.7775 - accuracy: 0.3586 - val_loss: 1.7763 - val_accuracy: 0.3453\n","Epoch 29/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.7540 - accuracy: 0.3685 - val_loss: 1.7671 - val_accuracy: 0.3621\n","Epoch 30/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.7481 - accuracy: 0.3579 - val_loss: 1.7598 - val_accuracy: 0.3681\n","Epoch 31/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.7537 - accuracy: 0.3610 - val_loss: 1.7501 - val_accuracy: 0.3765\n","Epoch 32/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.7368 - accuracy: 0.3569 - val_loss: 1.7341 - val_accuracy: 0.3801\n","Epoch 33/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.7317 - accuracy: 0.3651 - val_loss: 1.7406 - val_accuracy: 0.3801\n","Epoch 34/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.7224 - accuracy: 0.3730 - val_loss: 1.7219 - val_accuracy: 0.3669\n","Epoch 35/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.7264 - accuracy: 0.3644 - val_loss: 1.7316 - val_accuracy: 0.3705\n","Epoch 36/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.6897 - accuracy: 0.3826 - val_loss: 1.7250 - val_accuracy: 0.3765\n","Epoch 37/100\n","131/131 [==============================] - 11s 81ms/step - loss: 1.6867 - accuracy: 0.3836 - val_loss: 1.6947 - val_accuracy: 0.3885\n","Epoch 38/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.6894 - accuracy: 0.3850 - val_loss: 1.6760 - val_accuracy: 0.4125\n","Epoch 39/100\n","131/131 [==============================] - 12s 89ms/step - loss: 1.6746 - accuracy: 0.3860 - val_loss: 1.6820 - val_accuracy: 0.3945\n","Epoch 40/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.6695 - accuracy: 0.3949 - val_loss: 1.6405 - val_accuracy: 0.4005\n","Epoch 41/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.6734 - accuracy: 0.3857 - val_loss: 1.6512 - val_accuracy: 0.3945\n","Epoch 42/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.6498 - accuracy: 0.3992 - val_loss: 1.6502 - val_accuracy: 0.3801\n","Epoch 43/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.6573 - accuracy: 0.3949 - val_loss: 1.6332 - val_accuracy: 0.4041\n","Epoch 44/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.6357 - accuracy: 0.4016 - val_loss: 1.6414 - val_accuracy: 0.3861\n","Epoch 45/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.6395 - accuracy: 0.4001 - val_loss: 1.6608 - val_accuracy: 0.3981\n","Epoch 46/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.6149 - accuracy: 0.4037 - val_loss: 1.6139 - val_accuracy: 0.4161\n","Epoch 47/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5983 - accuracy: 0.4059 - val_loss: 1.6299 - val_accuracy: 0.4017\n","Epoch 48/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5976 - accuracy: 0.4133 - val_loss: 1.6326 - val_accuracy: 0.4041\n","Epoch 49/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.5923 - accuracy: 0.4258 - val_loss: 1.6278 - val_accuracy: 0.4005\n","Epoch 50/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5923 - accuracy: 0.4155 - val_loss: 1.6290 - val_accuracy: 0.4029\n","Epoch 51/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5837 - accuracy: 0.4196 - val_loss: 1.6094 - val_accuracy: 0.4101\n","Epoch 52/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.5547 - accuracy: 0.4340 - val_loss: 1.6034 - val_accuracy: 0.4305\n","Epoch 53/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.5819 - accuracy: 0.4225 - val_loss: 1.5897 - val_accuracy: 0.4149\n","Epoch 54/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.5605 - accuracy: 0.4246 - val_loss: 1.5949 - val_accuracy: 0.4077\n","Epoch 55/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5707 - accuracy: 0.4304 - val_loss: 1.6049 - val_accuracy: 0.4101\n","Epoch 56/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5475 - accuracy: 0.4342 - val_loss: 1.5762 - val_accuracy: 0.4125\n","Epoch 57/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.5332 - accuracy: 0.4359 - val_loss: 1.5875 - val_accuracy: 0.4149\n","Epoch 58/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.5334 - accuracy: 0.4359 - val_loss: 1.5966 - val_accuracy: 0.4137\n","Epoch 59/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.5184 - accuracy: 0.4501 - val_loss: 1.5671 - val_accuracy: 0.4365\n","Epoch 60/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.5221 - accuracy: 0.4429 - val_loss: 1.5720 - val_accuracy: 0.4221\n","Epoch 61/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.5053 - accuracy: 0.4479 - val_loss: 1.5676 - val_accuracy: 0.4365\n","Epoch 62/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.5434 - accuracy: 0.4340 - val_loss: 1.5478 - val_accuracy: 0.4388\n","Epoch 63/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.4890 - accuracy: 0.4551 - val_loss: 1.5542 - val_accuracy: 0.4185\n","Epoch 64/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.4878 - accuracy: 0.4508 - val_loss: 1.5702 - val_accuracy: 0.4269\n","Epoch 65/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.5058 - accuracy: 0.4561 - val_loss: 1.5647 - val_accuracy: 0.4185\n","Epoch 66/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.4744 - accuracy: 0.4623 - val_loss: 1.5607 - val_accuracy: 0.4329\n","Epoch 67/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4821 - accuracy: 0.4515 - val_loss: 1.5516 - val_accuracy: 0.4448\n","Epoch 68/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.4869 - accuracy: 0.4542 - val_loss: 1.5235 - val_accuracy: 0.4365\n","Epoch 69/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.4702 - accuracy: 0.4712 - val_loss: 1.5156 - val_accuracy: 0.4472\n","Epoch 70/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.4784 - accuracy: 0.4592 - val_loss: 1.5258 - val_accuracy: 0.4353\n","Epoch 71/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.4671 - accuracy: 0.4618 - val_loss: 1.5236 - val_accuracy: 0.4353\n","Epoch 72/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.4449 - accuracy: 0.4726 - val_loss: 1.5366 - val_accuracy: 0.4436\n","Epoch 73/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4289 - accuracy: 0.4722 - val_loss: 1.5349 - val_accuracy: 0.4376\n","Epoch 74/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.4393 - accuracy: 0.4767 - val_loss: 1.5312 - val_accuracy: 0.4305\n","Epoch 75/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.4286 - accuracy: 0.4837 - val_loss: 1.5077 - val_accuracy: 0.4508\n","Epoch 76/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4283 - accuracy: 0.4801 - val_loss: 1.5317 - val_accuracy: 0.4388\n","Epoch 77/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4106 - accuracy: 0.4861 - val_loss: 1.5428 - val_accuracy: 0.4388\n","Epoch 78/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.4381 - accuracy: 0.4731 - val_loss: 1.5146 - val_accuracy: 0.4556\n","Epoch 79/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4046 - accuracy: 0.4851 - val_loss: 1.5400 - val_accuracy: 0.4412\n","Epoch 80/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4191 - accuracy: 0.4808 - val_loss: 1.5095 - val_accuracy: 0.4460\n","Epoch 81/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.3875 - accuracy: 0.5060 - val_loss: 1.5342 - val_accuracy: 0.4448\n","Epoch 82/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.4037 - accuracy: 0.4777 - val_loss: 1.5382 - val_accuracy: 0.4281\n","Epoch 83/100\n","131/131 [==============================] - 11s 85ms/step - loss: 1.3817 - accuracy: 0.4897 - val_loss: 1.5382 - val_accuracy: 0.4388\n","Epoch 84/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.3626 - accuracy: 0.5017 - val_loss: 1.5290 - val_accuracy: 0.4388\n","Epoch 85/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.3774 - accuracy: 0.4938 - val_loss: 1.5061 - val_accuracy: 0.4604\n","Epoch 86/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3589 - accuracy: 0.5137 - val_loss: 1.5138 - val_accuracy: 0.4628\n","Epoch 87/100\n","131/131 [==============================] - 12s 88ms/step - loss: 1.3286 - accuracy: 0.5149 - val_loss: 1.4972 - val_accuracy: 0.4568\n","Epoch 88/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.3497 - accuracy: 0.5082 - val_loss: 1.5003 - val_accuracy: 0.4628\n","Epoch 89/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3504 - accuracy: 0.5067 - val_loss: 1.4997 - val_accuracy: 0.4568\n","Epoch 90/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.3497 - accuracy: 0.4986 - val_loss: 1.5138 - val_accuracy: 0.4520\n","Epoch 91/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.3439 - accuracy: 0.5137 - val_loss: 1.5070 - val_accuracy: 0.4556\n","Epoch 92/100\n","131/131 [==============================] - 11s 88ms/step - loss: 1.3240 - accuracy: 0.5182 - val_loss: 1.5053 - val_accuracy: 0.4592\n","Epoch 93/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3430 - accuracy: 0.5204 - val_loss: 1.4865 - val_accuracy: 0.4628\n","Epoch 94/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.3210 - accuracy: 0.5122 - val_loss: 1.5196 - val_accuracy: 0.4508\n","Epoch 95/100\n","131/131 [==============================] - 11s 86ms/step - loss: 1.3246 - accuracy: 0.5142 - val_loss: 1.4827 - val_accuracy: 0.4700\n","Epoch 96/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3201 - accuracy: 0.5154 - val_loss: 1.4893 - val_accuracy: 0.4688\n","Epoch 97/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3086 - accuracy: 0.5218 - val_loss: 1.5219 - val_accuracy: 0.4508\n","Epoch 98/100\n","131/131 [==============================] - 11s 87ms/step - loss: 1.3059 - accuracy: 0.5245 - val_loss: 1.4575 - val_accuracy: 0.4688\n","Epoch 99/100\n","131/131 [==============================] - 11s 84ms/step - loss: 1.2907 - accuracy: 0.5334 - val_loss: 1.4758 - val_accuracy: 0.4748\n","Epoch 100/100\n","131/131 [==============================] - 11s 83ms/step - loss: 1.2934 - accuracy: 0.5247 - val_loss: 1.4899 - val_accuracy: 0.4592\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAu8ElEQVR4nO3deXxU1f3/8deZJTPZd7YQCAoIYYewg0vdABVQXMDSilrBtVVbq9Z+rVX7be23P1utKyquFaHaBatWpQVZBCEgiCxKWDQJCIEkkD0zmfP740zIZCMTmGQyk8/z8ZgHmbk3M59r8M3J5557rtJaI4QQIvRZgl2AEEKIwJBAF0KIMCGBLoQQYUICXQghwoQEuhBChAlbsD44JSVFZ2RkBOvjhRAiJG3atOmI1jq1qW1BC/SMjAyys7OD9fFCCBGSlFLfNLdNWi5CCBEmJNCFECJMSKALIUSYCFoPXQghToXL5SIvL4/Kyspgl9KmnE4nPXv2xG63+/09LQa6UmoRcClwWGs9uIntCngCmAaUA/O01pv9rkAIIVohLy+P2NhYMjIyMPETfrTWHD16lLy8PPr06eP39/nTcnkFmHKS7VOBft7HfOBZvz9dCCFaqbKykuTk5LANcwClFMnJya3+LaTFQNdarwIKT7LLDOA1bawHEpRS3VtVhRBCtEI4h3mtUznGQPTQ04Bcn+d53tcONtxRKTUfM4qnV69ep/Zp334G+1ZB92HmEdv11N5HCCHCTLueFNVaLwQWAmRlZZ3aQuy562HFo3XPY7rVhXv3oebP+HToBP+CCyE6vpiYGEpLS9vlswIR6PlAus/znt7X2sbEn8Co6+G7bfDdF3Bwq3nkfAzaY/aJTPQJ+WHQbRgknQEWmaUphAhfgQj0ZcDtSqm3gLHAMa11o3ZLQDnjIGOiedSqLofDO+DgFjjoDfr1z0JNtdkeEQvdhtQP+pT+YJWZm0II/913332kp6dz2223AfDQQw9hs9lYsWIFRUVFuFwuHn30UWbMmNHutamWbkGnlFoMnAukAIeAXwF2AK31c95pi09hZsKUA9drrVtcpCUrK0u3+Vou7moo2FU3iv/uCzOyd5Wb7TYndB1UP+S7ZILN0bZ1CSFO2c6dOxk4cCAAv353OzsOHA/o+2f2iONXlw1qdvvnn3/OnXfeySeffGL2z8zkww8/JD4+nri4OI4cOcK4cePYvXs3SqnTarn4HmstpdQmrXVWU/u3ODzVWs9pYbsGbmtNke3GFuHtqw8FfmBe89TA0Zy6kD+4Fba9A9mLzHaLDVIHNmjZDIaI6KAdhhCi4xgxYgSHDx/mwIEDFBQUkJiYSLdu3bjrrrtYtWoVFouF/Px8Dh06RLdu3dq1ts7Xb7BYIfUs8xh6tXlNayjaXz/kv/43bHnD+00KUvo1CPmhEJkQpIMQQgAnHUm3pauuuoq3336b7777jmuuuYa//OUvFBQUsGnTJux2OxkZGUG5krXzBXpTlIKkPuYxaKZ5TWsoOVg/5L/5FLb9te77EjNMsHcfBt2Hmz9jmlymWAgRRq655hpuuukmjhw5wieffMLSpUvp0qULdrudFStW8M03za5w26Yk0JujFMT1MI+zpta9Xnakfsgf3Ao7l9Vtj+3ReBplXJpMoxQijAwaNIiSkhLS0tLo3r073//+97nssssYMmQIWVlZDBgwICh1SaC3VnQK9D3fPGpVHjMnW31DfveHddMoo5Lrt2q6D4PEPjKNUogQtm3bthNfp6SksG7duib3a6856CCBHhjOeMiYZB61qsvg0Pb6If/pU+Bxme2OOJ92jXc0n9xPplEKIU6ZpEdbiYiG9DHmUctdBYd31k2hPLjVzK5xV5jttkgzo8b35GvqQDNbRwghWiCB3p5sDugx3Dxq1bjh6G7vKN4b8l8shY0vmu0WO3QZCL0nQNYNZnaOEEI0QQI92Kw2E9hdBsKw2eY1jweK9tVv12S/DJ89B2ecC2MWQP+LzRRMIYTwkkDviCwWSD7TPAZfYV4rOwKbXjEtmrfmQEJvGHMTjJhr1q4RQnR6Ms0iVESnwNk/g598AVe9aqZCfvRLeDwT3v0JHNoR7AqFEEEmgR5qrDZz8dMNH8DNa2DwLNj6Fjw7Hl65FHa+a/ryQog2UVxczDPPPNPq75s2bRrFxcWBL8iHBHoo6zYEZjwFd++ECx4yyxcsmQtPDoc1f4Tyk91oSghxKpoLdLf75AOp999/n4SEhDaqypBADwdRSTDpLvjxFrjmDbMkwfKH4PGB8M/bzUVPQoiAuO+++9izZw/Dhw9n9OjRTJ48menTp5OZmQnAzJkzGTVqFIMGDWLhwoUnvi8jI4MjR46wf/9+Bg4cyE033cSgQYO46KKLqKioCEhtclI0nFhtMPAy8zi0HTYshK1L4PPXodcEGDsfBlwmFy+J8PHBfYEfsHQbAlN/1+zm3/3ud3z55Zds2bKFlStXcskll/Dll1/Sp08fABYtWkRSUhIVFRWMHj2aWbNmkZycXO89du/ezeLFi3nhhRe4+uqreeedd5g7d+5ply4j9HDVdRBc9gT8dCdc9Cgcz4e/zoMnhsKqP5hZM0KI0zZmzJgTYQ7w5JNPMmzYMMaNG0dubi67d+9u9D19+vRh+PDhAIwaNYr9+/cHpBYZqoW7yESYcAeMuxW+/hA2PA//fQQ++b05oTp2PvQYEewqhTg1JxlJt5fo6Lp7JaxcuZLly5ezbt06oqKiOPfcc5tcRtfhqLuJjtVqlZaLaCWLFQZMM4+Cr0w7Zsti2PompI+FMfMhcwZY7cGuVIgOLTY2lpKSkia3HTt2jMTERKKioti1axfr169v19qk5dIZpZ4Fl/w/0465+LdQehjeuRH+OBhWPmaeCyGalJyczMSJExk8eDD33HNPvW1TpkzB7XYzcOBA7rvvPsaNG9eutbV4T9G20i73FBX+8XggZ7lpx+QsN+vHDL7CLDHQc1SwqxOinqbusxmuAn5PUdEJWCzQ/yLzOLIbNrwAW96EL5ZA2igT7INmys2zhejgpOUi6kvpB9N+D3fvgKn/B5XH4e/zTTtmxf/C8YPBrlAI0QwJdNE0Z5yZAXPbBpj7jpkJ88nv4U+D4e0b4NvPzH1XhRAdhrRcxMlZLND3AvM4ugc2vmQuVPryHXNj7LELYNAVYHcGu1IhOj0ZoQv/JZ8JU/7XrB1zyf8DVwX84xb4Yyb852E4lh/sCoXo1CTQRes5YmD0j+C2z+CH/zTz2Fc/Dn8aAkuvg28+lXaMEEHgV6ArpaYopb5SSuUope5rYntvpdR/lFJfKKVWKqV6Br5U0eEoZe6gNGcx/GQLjL8V9q6Al6fCc5Nh82tmFC9EGDnV5XMB/vSnP1FeXh7giuq0GOhKKSvwNDAVyATmKKUyG+z2B+A1rfVQ4GHgt4EuVHRwiRlmzZi7d5k1ZHQNLLvDrPj48a+gODfYFQoREB050P05KToGyNFa7wVQSr0FzAB8b5GTCdzt/XoF8I8A1ihCSUQUjJoHI6+D/WvMxUqfPmkeZ02DsTdDxiQzuhciBPkun3vhhRfSpUsXli5dSlVVFZdffjm//vWvKSsr4+qrryYvL4+amhr+53/+h0OHDnHgwAHOO+88UlJSWLFiRcBr8yfQ0wDf4VUeMLbBPluBK4AngMuBWKVUstb6qO9OSqn5wHyAXr16nWrNIhQoBX0mm0dxLmS/BJtehV3/gi6ZZu2YoVdDRHTL7yVEMx7b8Bi7CncF9D0HJA3g3jH3Nrvdd/ncjz76iLfffpsNGzagtWb69OmsWrWKgoICevTowXvvvQeYNV7i4+N5/PHHWbFiBSkpKQGtuVagTor+DDhHKfU5cA6QD9Q03ElrvVBrnaW1zkpNTQ3QR4sOLyHd3FHp7h0w/SmzUNi/7jTtmA8fMHdaEiIEffTRR3z00UeMGDGCkSNHsmvXLnbv3s2QIUP4+OOPuffee1m9ejXx8fHtUo8/I/R8IN3neU/vaydorQ9gRugopWKAWVrr4gDVKMKFPRJG/gBGzIVv15t2zPpnYd3TcNZUM2o/41xpxwi/nWwk3R601tx///0sWLCg0bbNmzfz/vvv88tf/pLzzz+fBx98sM3r8WeEvhHop5Tqo5SKAGYDy3x3UEqlKKVq3+t+YFFgyxRhRSnoPR6uegXu3AaTfwq5G+D1mfD0WNj4IlSVBrtKIZrku3zuxRdfzKJFiygtNX9f8/PzOXz4MAcOHCAqKoq5c+dyzz33sHnz5kbf2xZaHKFrrd1KqduBDwErsEhrvV0p9TCQrbVeBpwL/FYppYFVwG1tVrEIL/FpcP7/wNn3wPa/w2fPwXs/heUPw4jvm/nuyWcGu0ohTvBdPnfq1Klce+21jB8/HoCYmBjeeOMNcnJyuOeee7BYLNjtdp599lkA5s+fz5QpU+jRo0ebnBSV5XNFx6I15G2Ez56HHf8ATw30u9AsMXDG98xSBKJTk+VzZflcESqUgvQx5lHyG8h+GbIXwRuzILmv6bMPm2MWDxNC1CPDHdFxxXaD8+6Hu7bDFS+AMwE++Dk8ngnv/xyO5AS7QiE6FBmhi47PFmHmrA+9GvI3wWcLzah9w/Nw5vmmHdP3QmnHdCJaa1SYz4Y6lXa4/B8gQkvaKLjieTOn/bwH4NB2ePNqeGoUrHsGKo8Fu0LRxpxOJ0ePHj2lwAsVWmuOHj2K09m6ZanlpKgIbTUu2LnMnETN/Qzs0TBstum1dxkQ7OpEG3C5XOTl5VFZWRnsUtqU0+mkZ8+e2O32eq+f7KSoBLoIHwe2wIaFsO1tqKkyFymNWQD9LzZXpwoRBiTQRedSdgQ2v2rurnQ8HxJ6m/nsI38AkYnBrk6I0yKBLjqnGrdZDGzDQvhmLdgizYnVsQug66BgVyfEKZF56KJzstpg0Ezz+G6b6bN/scSM3jMmmz77WdPMfkKEARmhi86lvNDcSWnji3AsF+LTYfSNZv32qKRgVydEi6TlIkRDNW74+gMzat+/GmxOGHKlOYnafWiwqxOiWdJyEaIhqw0GXmYeh3aYPvsXS+DzN6DXeNNnH3ApWO0tv5cQHYSM0IWoVVFkAn3DC1D8DcT2gNE3wKjrIbpt7jAjRGtJy0WI1vDUwO6PTDtm7wqwRsDgK2HsfOgxItjViU5OWi5CtIbFau6gdNZUKPjKtGO2LIatb0LPMaYdM3C6WWNGiA5ERuhC+KPyGGx504R74V6I6QZZN8CoeRDbNdjViU5EWi5CBIrHAznLzUqPOcvBYodBl5tRe88m/x8TIqCk5SJEoFgs0P8i8ziSAxtfgM//AtuWmpUgxywwFzLZHMGuVHRCMkIX4nRVlZge+4aFcHQ3RKeamTFZN0Bc92BXJ8KMtFyEaA8ej5kV89nzZpaMxQqZM8yoPX2Mub2eEKdJWi5CtAeLBfqebx6Fe2HDi2Ze+5fvQPdhJtgHzwJ7625aIIS/ZIQuRFuqKjVXoG5YCAW7ICrZzIzJuhHi04JdnQhB0nIRIti0hn2fmPuhfvU+KAsMvBTG3myWGpB2jPCTtFyECDalzB2UzjgXivab1R43vw47/gldh5irUIdcBfbIIBcqQplfN4lWSk1RSn2llMpRSt3XxPZeSqkVSqnPlVJfKKWmBb5UIcJEYgZc9CjcvRMuewK0B5bdAY8PhJWPQXV5sCsUIarFQFdKWYGngalAJjBHKZXZYLdfAku11iOA2cAzgS5UiLATEWX66beshXnvQa8JsPJ/4aks2LrEzJoRohX8GaGPAXK01nu11tXAW8CMBvtoIM77dTxwIHAlChHmlIKMSTDnTbj+AzOP/e/z4aULIHdDsKsTIcSfQE8Dcn2e53lf8/UQMFcplQe8D9zR1BsppeYrpbKVUtkFBQWnUK4QYa73BLhpBcx8Do4fgJcuhLdvgOJvg12ZCAF+9dD9MAd4RWvdE5gGvK6UavTeWuuFWussrXVWampqgD5aiDBjscDwOXDHJjjnXtj1Hjw1Gv7ziJkGKUQz/An0fCDd53lP72u+bgSWAmit1wFOQO4IIMTpiIiG834Bt2ebOyut/gP8eZRZO0b666IJ/gT6RqCfUqqPUioCc9JzWYN9vgXOB1BKDcQEuvRUhAiEhHSY9SLcuBzie8I/b4UXzoX9a4NdmehgWgx0rbUbuB34ENiJmc2yXSn1sFJqune3nwI3KaW2AouBeTpYVywJEa7SR8OPlsMVL0LZUXhlGiz5ARTuC3ZlooOQK0WFCEXV5bDuaVjzOHjcMO4WmPwzcMa1/L0ipJ3sStFAnRQVQrSniCg45x64Y7O53+naJ+DPI2HTK+aeqKJTkkAXIpTFdYfLnzVTHZP7wrs/gefPhr0rg12ZCAIJdCHCQdpIc1HSVa9C1XF4bQYsngNH9wS7MtGOJNCFCBdKmdvf3bYRzv8V7FsNT4+Ff/8CKoqCXZ1oBxLoQoQbuxMm3w0/3gzDr4X1z8CTI2HDC1DjDnZ1og1JoAsRrmK6wPQnYcEq6DoI3v8ZPDcRcpYHuzLRRiTQhQh33YfCde/C7DfBXQVvzII3roSCr4JdmQgwCXQhOgOlYMAlcNtnZi323A3wzHh4/x4oLwx2dSJAJNCF6ExsDphwh+mvj5pn7pz05HBY9wy4q4NdnThNEuhCdEbRKXDp43DzWkgbBR/eD8+Oh6/+be5/KkKSBLoQnVnXTJj7N7j2r4CCxdfA6zPh0PZgVyZOgQS6EJ2dUtD/Irh1HUz9PRzYAs9NgnfvhFJZNDWUSKALIQyrHcYugB9/DmPmw+evm/Vh1j5hZseIDk8CXQhRX1QSTH0MblkHvcbDxw/C02Ng57vSX+/gJNCFEE1L7Q/fX2p67LZIWDIXXrkUDm4NdmWiGRLoQoiT63s+3LwGLnkcCnbC8+fAP2+Dku+CXZloQAJdCNEyqw1G32jWXx9/G2xdYu5vuuoP4KoIdnXCSwJdCOG/yAS4+DfmitMzzoX/PgJPjYEv35H+egcggS6EaL3kM2H2X8waMc54ePsGWDQF8jcFu7JOTQJdCHHq+pwNCz6B6X+Gwr3wwvfgbwvg+IFgV9YpSaALIU6PxQojfwh3bIJJd8H2v5v++srfmZtZi3YjgS6ECAxnHFzwENy+AfpdBCt/C09lmROoHk+wq+sUJNCFEIGVmAFXv2rucRqdCn+fDy9dYJbsFW1KAl0I0TZ6T4CbVsDMZ01P/aULzcnT4m+DXVnYkkAXQrQdi8Xc1/SOTXDOvbDrPXhqNPznEagqDXZ1YcevQFdKTVFKfaWUylFK3dfE9j8qpbZ4H18rpYoDXqkQInRFRMN5v4Dbs2HgZbD6D2bhr8/fkP56ALUY6EopK/A0MBXIBOYopTJ999Fa36W1Hq61Hg78GfhbG9QqhAh1Cekw60W4cTnEp5slBF44F/avDXZlYcGfEfoYIEdrvVdrXQ28Bcw4yf5zgMWBKE4IEabSR8OPlsMVL0LZUXhlGiz5ARTuC3ZlIc2fQE8Dcn2e53lfa0Qp1RvoA/y3me3zlVLZSqnsggJZOF+ITk0pGHoV3L4RznsAcpabZXo/fhAqjwe7upAU6JOis4G3tdY1TW3UWi/UWmdprbNSU1MD/NFCiJAUEQXn/Nws/DX4SnNDjT+PhOyXwdNklIhm+BPo+UC6z/Oe3teaMhtptwghTkVcd7j8WTPVMbkv/OtOeP5s2Lsy2JWFDH8CfSPQTynVRykVgQntZQ13UkoNABKBdYEtUQjRqaSNNBclXfUqVB2H12bA4jlwdE+wK+vwWgx0rbUbuB34ENgJLNVab1dKPayUmu6z62zgLa1lDU0hxGlSCgbNhNs2wvm/gn2r4Omx8O9fQEVRsKvrsFSw8jcrK0tnZ2cH5bOFECGm5BCseBQ2vw6RiWZO+6jrzY03Ohml1CatdVZT2+RKUSFExxfb1SzRu2AVdB0E7/8MnpsIu5cHu7IORQJdCBE6ug81N9WY/Sa4q+Avs+CNK6Hgq2BX1iFIoAshQotSMOAScxu8ix41qzg+Mx7evwfKC4NdXVBJoAshQpPNARPugB9vhlHzYOOL8ORwWPcMuKuDXV1QSKALIUJbdApc+jjcvBbSRsGH98Oz4+GrDzrdjasl0IUQ4aFrJsz9G1z7V0DB4tnw+kw4tD3YlbUbCXQhRPhQCvpfBLeug6m/hwNb4LlJ8O6dUBr+60dJoAshwo/VDmMXwI8/hzHz4fPXzfowa58ws2PClAS6ECJ8RSXB1MfglnXQa7xZyfHpMbDz3bDsr0ugCyHCX2p/+P5S02O3RcKSufDKpXBwa7ArCygJdCFE59H3fLh5DVzyOBTshOfPMXdNKvku2JUFhAS6EKJzsdpg9I1m/fXxt8HWJfDnUbDqD+CqCHZ1p0UCXQjROUUmwMW/MVecnnEu/PcReGoMfPlOyPbXJdCFEJ1b8pkw+y9mjRhnPLx9AyyaAvmbgl1Zq0mgCyEEQJ+zYcEncNmTULgXXvge/G0BHGvuBm0djwS6EELUslhh1HVwxyaYdBds/7vpr6/8HVSXB7u6FkmgCyFEQ844uOAhuH0D9L8YVv4WnsoyJ1A9nmBX1ywJdCGEaE5iBlz9qrnHaXQq/H0+vHSBWbK3A5JAF0KIlvSeADetgJnPmp76Sxeak6fF3wa7snok0IUQwh8WCwy/1vTXz/457HoPnhoN/3kEqkqDXR0ggS6EEK3jiIHvPQC3Z8PAy2D1H8zCX5+/EfT+ugS6EEKcioR0mPUi3Lgc4tPNEgIvnAv71watJAl0IYQ4Hemj4UfL4YoXoewovDINlvwACve1eykS6EIIcbqUgqFXwe0b4bwHIGe5Wab34weh8ni7lSGBLoQQgRIRBef83Jw4HXyluaHGkyMg+2Xw1LT5x/sV6EqpKUqpr5RSOUqp+5rZ52ql1A6l1Hal1JuBLVMIIUJIXA+4/Fkz1TGlH/zrTnj+bNi7sk0/tsVAV0pZgaeBqUAmMEcpldlgn37A/cBErfUg4M7AlyqEECEmbaS5KOmqV6HqOLw2AxbPgSM5bfJx/ozQxwA5Wuu9Wutq4C1gRoN9bgKe1loXAWitDwe2TCGECFFKwaCZcNtGOP9XsG8VfLuuTT7K5sc+aUCuz/M8YGyDffoDKKXWAlbgIa31vxu+kVJqPjAfoFevXqdSrxBChCa7EybfDSPmQlRym3xEoE6K2oB+wLnAHOAFpVRCw5201gu11lla66zU1NQAfbQQQoSQmC5mVcc24E+g5wPpPs97el/zlQcs01q7tNb7gK8xAS+EEKKd+BPoG4F+Sqk+SqkIYDawrME+/8CMzlFKpWBaMHsDV6YQQoiWtBjoWms3cDvwIbATWKq13q6UelgpNd2724fAUaXUDmAFcI/W+mhbFS2EEKIxpYN0M9SsrCydnZ0dlM8WQohQpZTapLXOamqbXCkqhBBhQgJdCCHChAS6EEKECQl0IYQIExLoQggRJiTQhRAiTEigCyFEmJBAF0KIMCGBLoQQYUICXQghwoQEuhBChAkJdCGECBMS6EIIESYk0IUQIkxIoAshRJiQQBdCiDAhgS6EEGFCAl0IIcKEBLoQQoQJCXQhhAgTEuhCCBEmJNCFECJM2IJdgBCdiavGRamrlNLqUvOnq5QyV5n5s7oMm8VGojORJGcSSc4kEp2JxNhjUEoFu3QRAiTQhWiB1ppqTzWl1T7h6yprHMrV9QO6qf2rPdWt/ny7xU6iI5GkyCQSHYknAr/Rn95tcRFx8g9AJyWBLsKW1pqqmqqTBrBv+NYbLftsL3GV4Pa4W/w8CzZsKhIrkSjtBI8TXRNBjbsLLncE1dUOPDUOtMc8qHF6v3aia5zgcYByo2xlKGsZMVGVJMe7iIuuxGGtwOIpo7DyOLkluRRVFVHmKmuyDpsyo/zaR5KjifD32RbniMOipPsaDvwKdKXUFOAJwAq8qLX+XYPt84D/A/K9Lz2ltX4xgHWKTkRrTYW7on64elsStYFcL4ybGSGXVZfh1i0HsVXZsatIbERiIRLlcaI9Tjw18bjdEWhXBO5qO263A11jApgTQewwwe1xgLYR47AT57QR67QT67QRF2knNsZmvnba67/utBHX4PXCsmr2FJSSc7j0xJ85u0spKnedqDfSbuXMLtFkpUSQluQhJcFFfHQVEY4KjlUXUVRZRFFVEYWVhRRVFvFl6ZcUVRZR6ipt5vitJDgSmh75O+rCP9mZTKIzkXhHvPwD0EEprfXJd1DKCnwNXAjkARuBOVrrHT77zAOytNa3+/vBWVlZOjs7+1RqFh1UbRCfCNlqM7ptOBpudlRcXbe9Rte0+Hk2FUGEJQq7isKKE4t2gjYhW+N24HZHUO2KoKoqgspquwldbwibUK4LYgCn3VIXuD5/xkV6A9pRF8SxzsbBHeOwYbW0TavjaGmVCffakD9cyp7DpRw4Vln338Oi6JUcRd/UGPp2qXucmRpDtMNGdU11vbCvDfyiyrrwL6wsPLG9pLqkyVosymL+AWim/XMi/L3bExwJWC3WNvnv0hkppTZprbOa2ubPCH0MkKO13ut9s7eAGcCOk36XCBke7aHCXUFJdUmT4dpU+DYcMZdVl1HmLsOjPS1+XoTFicMShd0SaVoU2onSCeDpRlSNgwh3BG5XBFUuO5VVEVRU2fG4HXXtCY8Dahz4/vW1WVS9kW+sw05ctO3kAe3zeqzTToSt4446k2McJMc4GHtGcr3Xy6rc7C0oI6eg5ETQ5xwu5b+7DuP21A3WesQ7OdMb7iboz2JclxiSoyOa7be7PC6KK4vrh39Vg/CvLOLroq8pqiriWNWxJt9HoYh3xNc/2etIbDTyr92e4EjAZpFu8Knw579aGpDr8zwPGNvEfrOUUmdjRvN3aa1zG+6glJoPzAfo1atX66sV9dR4aih3lzdqN5S4ShoFcqMess/2MlcZmpP/pgbgsEbitEYRYYkionZUTAqRnjScOEkggpoaB9UuB1XVdiqq7FRU2qh2RZgwru0TU3+0phTEOOrCNbE2ZBMajohrvzavx/m87rRbOuWJwGiHjSE94xnSM77e69VuD98WltUL+ZyCUpZszKXCVffbT0KUvd6I/swuMfRNjSEtIRK7xU5qVCqpUal+1eL2uCmuKm488q8qorCibuS/p3gPRZVFFFcVN/v3Lt4Rb04E+4z6Ex2JJEcmN/rNINGRiN1qP/X/iGHEn5bLlcAUrfWPvM9/AIz1ba8opZKBUq11lVJqAXCN1vp7J3tfabm0zFXjYtPhTazJW8PXRV836hk3d1KsoShbNE5rFE6raU+YE3e1LYpIPG4HNTUO3C471S7TnqisslNWYae8srZVEUHDIK4VabfWC1rf0W9cvde9I+fI+sEcE2HD0katClGfx6M5eLyyXtDv8YZ9YVndDJxIu5UzUqN9RvTmkZEcHbDfZGo8NRRXFTfZBvL9jaD2eXFVcbO/AcZGxNYb+ftO+2x4YjjJmRTS/wCcbsslH0j3ed6TupOfAGitj/o8fRH4fWuLFMbB0oOszl/Nmvw1fHbwM8rd5dgtdtKj++K0xhCtEoi1O1E2Jzgc1NQ4cbsjcHtHxZVVdiqqbJRW2CirtFHjjqDkJNeP2a2qXj84xWkjLt5nVNygPRHXxOt2a8dtVYj6LBZFWkIkaQmRnNO//si7sKy60Yh+0zdFLNt64MQ+Vouid1KUGcl7R/O1I/sYR+vaJFaLleTIZJIjk1veGfMPwPHq4ycC/kT4V9X9RlBUWURuSS5fFHxBcVVxs+diYuwx9do8Df8xaPiPgsPqaNWxBYs/I3Qbpo1yPibINwLXaq23++zTXWt90Pv15cC9WutxJ3tfGaEbrhoXnx/+nDX5a1idv5qc4hwAekT3YHjKOEqL+7L6iwSOlzcOTaUg1lH/xFxcMyfsGp7Ii/O+7rB1zlaF8F95tbdP3yDs9x8pq9en7xbnbNS66dslhpSY5vv0bcmjPZRUlzQ78i+sKGz0j0Fzs6KibFGN+v1NjfxrX4+0RbbZcZ1shN5ioHvfYBrwJ8zv3Iu01r9RSj0MZGutlymlfgtMB9xAIXCL1nrXyd6zMwf6d2XfsSZ/DWvy17D+4HrKXOYKwVFdRzGpxyQS1FD+vdnDRzsOATBlcDemD0sjOSai3om8aGlViCBy1Xj45mh5/SmW3q/Lq+tGxvGR9nqj+dpHWkJkh/r7q7WmxFVSr9/vey6gqRPDLo+ryfeKtEU2OvnrO/If0WUEveN6n1Kdpx3obaEzBbrL42LL4S0nWim7i3YD0C26G5PTJjMpbRLDU7P4747jvLx2H9sPHCc+0s7sMen8cHwGaQlt96+9EIGmtebgscp6o/naXv1Rnz69w2bhjNSYRmGfkRKFw9bxpzlqrSl1lTYe+TcxJbT2ee2Vwg+Of5Cr+l91Sp8rgR4Eh8oOsfbAWlbnrWb9wfWUukqxKRsju448EeJnJpxJQUkVb6z/hjc3fMuR0mr6dYlh3sQMLh+RRlSETN0S4aWorLr+XHrv13lFFSf2sVoUvZKiGp2QPTM1mlhn6J7M1FpT7i6nsLKQuIg44h3xLX9TE073pKjwg8vjYuvhrSdaKV8VfQVA16iuXJxxMZPTJjO2+1hiImIA2JpbzF0fbuG9bQdxezTfO6sL10/sw8S+ydLTFmErMTqC0dFJjM5Iqvd6RXUNewrqt25yDpfyydeHcdXUDTq7xjkanYzt2yWG1BhHh///RilFtD2aaHt0232GjNBPXUF5wYmTmesPrKfEVYJN2RjRdQST0iYxKW0S/RL6nfiL5qrx8MGX3/HK2n1s/raYGIeNK0f1ZN6EDDJS2u6HLESoctV4+LawvN6Ifo/36zKfPn2c01ZvNG9CP5a0xMg2u3o3WKTlEiBuj5svCr44EeK7Cs153y6RXZjc07RRxnUfd2IUXquwrJrFG77l9XXf8N3xSjKSo7huQgZXjuoZ0r9CChEsWmu+azCfvjbwj5TW79P3SYluFPZ9UqJDok/fFAn003Ck4siJNsqnBz6lpLoEq7IyvMtwJqVNYnLaZPon9m/y172dB4/zytr9/GNLPlVuD5P6pnD9xAzOO6tLhzq7L0Q4KS6vbtSjzykwffrauLMo6JUU1WiK5ZldYojr4IMs6aG3Qo2nhm1HtrEqbxVr8tews3AnAKmRqVzQ6wIzCu8xjriIuGa+X7N85yFeXruP9XsLcdotzPK2Vfp3jW3PQxGiU0qIiiArI4msJvr0e4/UvzrW9OkLGvXp652Q9X6dGhsCfXoZoZtR+KcHPmV13mo+PfApx6uPY1VWhqUOO9FKOSvxrJP+MI9VuPhrdi6vrttPbmEFPeKd/HBCBrNHp5MQFdGORyOEaA23t0+/x/fiKW+vvrSq7kKj2No+fYPZNz0To9q1Ty8tlwZqR+G1rZTtR81FrymRKUzsMZFJPScxvvt4v6YV7Sko5dVP9/P2pjzKq2sYk5HEvIkZXJTZFZtcEi9EyNJac+i4d9niwyU+0y3LOFJadWK/CJuFM1Ki67Vuavv0Tnvg+/QS6EBhZSFr89eyOt+Mwo9VHcOiLAxLHXZiRsqApAF+Ldzv8WhW7S7glU/3s/KrAiKsFi4b1oPrJ2YwOO3U5pYKIULHsXLXiVG877z63KLyen369KSoRlMs+55mn75T9tBrPDVsP7rdzEjJW832o9vRaJKcSZzT8xwmp01mfA//RuG1yqrc/G1zHi9/up+9BWWkxjq464L+XDu2F6mxobF4jxDi9MVH2RnVO5FRvRPrvV7pqvGuT+/Tqz9cyurdR6iuqVsp8tfTB3HdhIyA1xVWgV5UWcTaA2tZk7+GtflrKa4qRqEYmjqUW4ffyuSekxmYNLDVt8/KLSzntXX7eWtjLiWVbob1jOdP1wxn2pDuHfqmCEKI9uW0W8nsEUdmj/qTJmo8mtza+fQFpY0urAqUkA50j/aw4+gOVueZNVK2Hdl2YhRee3n9hB4TSHAmtPq9tdas31vIy2v3sXznIZRSTB3cjesn9mFkr4QOf7ZbCNFxWC2KjJRoMlKiuYCubfY5IRfoxZXFfHrgUzMKP7CWwspCFIohKUO4ZfgtTE6bTGZy5infxLbSVcOyLQdYtHYfu74rITHKzi3nnsnccb3pHi+LZAkhOq6QC/S3vnqLp7c8TaIjkQlpE5icNpkJPSaQ6Exs+ZtP4rtjlby+fj+LN+RSWFbNgG6xPDZrCDOGp7XJmWohhAi0kAv0mX1nMqHHBAYlDwrIncQ3f1vEy2v388G2g9RozYUDuzJvYgbjz5BFsoQQoSXkAr1bdDe6RXc7rfeodnv44MuDLFq7n625xcQ6bcybkMF1EzJIT4oKUKVCCNG+Qi7QT8eR0ire/Oxb3lj/DYdLqjgjJZqHZwxi1sieRLfyfohCCNHRdIoU237gGC+v3c+yrQeodns4p38qj12ZwTn9UmWRLCFE2AjbQHfXePh4xyFe/nQ/G/YVEhVh5ZqsdK6bkEHfLjEtv4EQQoSYsAv0Y+Uu3tr4La+t+4b84gp6JkbywLSBXD06nfjIjr0sphBCnI6wCfScwyW8vHY/f9ucT4WrhnFnJPHgZZlcMLBr2N2xRAghmhLSge7xaFZ+fZiX1+5n9e4jRNgszBzeg3kT+jS69FYIIcJdSAZ6aZWbt7NzeXXdN+w7UkbXOAf3XHwWs0enkxwji2QJITqnkAv0pRtzeeRfOyipcjOiVwJPzhnB1MHdsMva40KITi7kAr1HQiTfG9iF6yf2YXh6QrDLEUKIDsOvYa1SaopS6iulVI5S6r6T7DdLKaWVUk0uvh4Ik/ql8MTsERLmQgjRQIuBrpSyAk8DU4FMYI5SKrOJ/WKBnwCfBbpIIYQQLfNnhD4GyNFa79VaVwNvATOa2O8R4DGgMoD1CSGE8JM/gZ4G5Po8z/O+doJSaiSQrrV+72RvpJSar5TKVkplFxQUtLpYIYQQzTvtqSFKKQvwOPDTlvbVWi/UWmdprbNSU1NP96OFEEL48CfQ84F0n+c9va/VigUGAyuVUvuBccCytjwxKoQQojF/An0j0E8p1UcpFQHMBpbVbtRaH9Nap2itM7TWGcB6YLrWOrtNKhZCCNGkFgNda+0Gbgc+BHYCS7XW25VSDyulprd1gUIIIfzj14VFWuv3gfcbvPZgM/uee/plCSGEaC2ltQ7OBytVAHxzit+eAhwJYDmhQI65c5Bj7hxO55h7a62bnFUStEA/HUqpbK11pzrpKsfcOcgxdw5tdcyyopUQQoQJCXQhhAgToRroC4NdQBDIMXcOcsydQ5scc0j20IUQQjQWqiN0IYQQDUigCyFEmOjQgd7SjTWUUg6l1BLv9s+UUhlBKDOg/Djms5VSm5VSbqXUlcGoMdD8OOa7lVI7lFJfKKX+o5TqHYw6A8mPY75ZKbVNKbVFKbWmqXsQhJqOdKOc9uDHz3ieUqrA+zPeopT60Wl/qNa6Qz4AK7AHOAOIALYCmQ32uRV4zvv1bGBJsOtuh2POAIYCrwFXBrvmdjrm84Ao79e3dJKfc5zP19OBfwe77rY+Zu9+scAqzJpQWcGuu41/xvOApwL5uR15hO7PjTVmAK96v34bOF8ppdqxxkBr8Zi11vu11l8AnmAU2Ab8OeYVWuty79P1mBU/Q5k/x3zc52k0EOqzFzrbjXL8Pd6A6siB3uKNNXz30WYRsWNAcrtU1zb8OeZw09pjvhH4oE0rant+HbNS6jal1B7g98CP26m2thKwG+WECH//Xs/ythLfVkqlN7G9VTpyoAtRj1JqLpAF/F+wa2kPWuuntdZnAvcCvwx2PW2pNTfKCSPvAhla66HAx9R1G05ZRw70lm6sUW8fpZQNiAeOtkt1bcOfYw43fh2zUuoC4AHMWvtV7VRbW2ntz/ktYGZbFtQOOtuNclr8GWutj/r8XX4RGHW6H9qRA/2kN9bwWgZc5/36SuC/2nu2IUT5c8zhpsVjVkqNAJ7HhPnhINQYaP4ccz+fp5cAu9uxvrbQ2W6U48/PuLvP0+mY+02cnmCfDW7hTPE04GvM2eIHvK89jPlBAziBvwI5wAbgjGDX3A7HPBrTjyvD/DayPdg1t8MxLwcOAVu8j2XBrrkdjvkJYLv3eFcAg4Jdc1sfc4N9VxLCs1z8/Bn/1vsz3ur9GQ843c+US/+FECJMdOSWixBCiFaQQBdCiDAhgS6EEGFCAl0IIcKEBLoQQoQJCXQhhAgTEuhCCBEm/j/RgFSUYrgYJgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}],"source":["t1 = []\n","t2 = []\n","t3 = []\n","\n","dropout_rates = [0,0.1,0.3,0.5]\n","\n","    # Add dropout after the second and third block\n","for dropout_rate in dropout_rates:\n","    model = ResNet18_d(num_classes,1,0,0,0,dropout_rate)\n","    \n","    model = adam_opt(model,0.00001)\n","\n","    \n","    model.fit(X_train, Y_train, batch_size=32,validation_data=(X_val, Y_val),epochs=100,verbose=1)\n","\n","    # Evaluate the model on the test set\n","    _,val_acc = model.evaluate(X_val, Y_val, verbose=0)\n","    _,train_acc = model.evaluate(X_train, Y_train, verbose=0)\n","    _, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n","\n","    t1.append(val_acc)\n","    t2.append(train_acc)\n","    t3.append(test_acc)\n","\n","plt.plot(dropout_rates,t1)\n","plt.plot(dropout_rates,t2)\n","plt.plot(dropout_rates,t3)\n","\n","plt.legend([\"val\",\"train\",\"test\"])\n","plt.show()"]},{"cell_type":"markdown","source":[],"metadata":{"id":"yzfBEntmCkVd"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}